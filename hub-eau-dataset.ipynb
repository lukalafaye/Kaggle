{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lukalafaye/hub-eau-dataset?scriptVersionId=211026657\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import requests\nimport pandas as pd\n\ndef fetch_all_data(url, output_file, params, date_key_api, date_key):\n    size = 20000\n    response = requests.get(url, params)\n    done = True\n    if response.status_code not in  [200, 206]:\n        done = False\n        print(f\"Error: {response.status_code} - {response.text}\")\n        \n    with open(output_file, 'wb') as f : \n        f.write(response.content)\n\n    stop = 20000\n    while True:\n\n        if stop != size : \n            done = True\n            break\n\n        with open('temp.csv', 'wb') as f : \n            f.write(response.content)\n\n        df = pd.read_csv('temp.csv', sep=\";\")\n        \n        stop = len(df)\n        \n        # the dataset is already sorted by date\n        \n        last_date = df.tail(1)[date_key].iloc[0]\n        # Convertir en datetime\n        last_date = pd.to_datetime(last_date)\n        print(\"last date:\", last_date)\n        # Ajouter un jour\n        next_date = last_date + pd.Timedelta(days=1)\n        print(\"next:\", next_date)\n\n\n        print(last_date)\n        params[date_key_api] = next_date\n        response = requests.get(url, params)\n\n        if response.status_code not in  [200, 206]:\n            done = False\n            print(f\"Error: {response.status_code} - {response.text}\")\n            break\n\n        with open(output_file, 'ab') as f : \n            f.write(response.content)\n        \n    print(\"DONE\", done)\n    return ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:40:47.567809Z","iopub.execute_input":"2024-12-03T14:40:47.569223Z","iopub.status.idle":"2024-12-03T14:40:47.579573Z","shell.execute_reply.started":"2024-12-03T14:40:47.56917Z","shell.execute_reply":"2024-12-03T14:40:47.57811Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"params = {\n    \"size\" : 20000,\n    \"code_departement\": \"75,77,78,91,92,93,94,95\",\n    \"fields\": \"code_station,libelle_station,code_commune,libelle_commune,latitude,longitude,code_ecoulement,libelle_ecoulement,date_observation\",\n    \"date_observation_min\": \"2023-01-01\",\n}\n\ndate_key_api = \"date_observation_min\"\ndate_key = \"date_observation\"\n\nurl = \"https://hubeau.eaufrance.fr/api/v1/ecoulement/observations.csv\"\noutput_file = \"analyses_ec.csv\"\n\nfetch_all_data(url, output_file, params, date_key_api, date_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:41:37.395687Z","iopub.execute_input":"2024-12-03T14:41:37.396222Z","iopub.status.idle":"2024-12-03T14:41:39.049466Z","shell.execute_reply.started":"2024-12-03T14:41:37.396183Z","shell.execute_reply":"2024-12-03T14:41:39.048075Z"}},"outputs":[{"name":"stdout","text":"last date: 2023-03-22 00:00:00\nnext: 2023-03-23 00:00:00\n2023-03-22 00:00:00\nDONE True\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"params = {\n    \"size\" : 20000,\n    \"fields\": (\n        \"code_commune,nom_commune,date_prelevement,libelle_parametre,\"\n        \"resultat_numerique,libelle_unite,conclusion_conformite_prelevement\"\n    ),\n    \"code_departement\": \"75,77,78,91,92,93,94,95\",\n    \"date_min_prelevement\": \"2014-01-01\",\n}\n\ndate_key_api = \"date_min_prelevement\"\ndate_key = \"date_prelevement\"\n\nurl = \"https://hubeau.eaufrance.fr/api/v1/qualite_eau_potable/resultats_dis.csv\"\n\n\noutput_file = \"analyses_qu.csv\"\n\nfetch_all_data(url, output_file, params, date_key_api, date_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:42:26.109561Z","iopub.execute_input":"2024-12-03T14:42:26.110051Z","iopub.status.idle":"2024-12-03T14:42:46.068151Z","shell.execute_reply.started":"2024-12-03T14:42:26.110013Z","shell.execute_reply":"2024-12-03T14:42:46.066734Z"}},"outputs":[{"name":"stdout","text":"last date: 2024-09-19 11:58:00+00:00\nnext: 2024-09-20 11:58:00+00:00\n2024-09-19 11:58:00+00:00\nlast date: 2024-09-20 08:05:00+00:00\nnext: 2024-09-21 08:05:00+00:00\n2024-09-20 08:05:00+00:00\nDONE True\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import requests\nimport pandas as pd\n\n# Juste un code r√©seau pour cette api...\n\nurl = \"https://hubeau.eaufrance.fr/api/v1/ecoulement/observations\"\nparams = {\n    \"format\": \"json\",\n    \"code_departement\": \"75,77,78,91,92,93,94,95\",\n    \"fields\": \"code_station,libelle_station,code_commune,libelle_commune,latitude,longitude,code_ecoulement,libelle_ecoulement,date_observation\",\n    \"date_observation_min\": \"2014-01-01\",\n    \"date_observation_max\": \"2024-12-31\"\n}\nresponse = requests.get(url, params=params)\n\nif response.status_code == 200:\n    data = response.json()[\"data\"]\n    \n    df_ecoulement = pd.DataFrame(data)\n    \n    \"\"\"\n    df_ecoulement[\"code_reseau\"] = df_ecoulement[\"code_reseau\"].apply(\n        lambda x: x if isinstance(x, list) else [x]\n    )\n    df_ecoulement_expanded = df_ecoulement.explode(\"code_reseau\")\n    \"\"\" \n    \n    df_ecoulement_expanded=df_ecoulement\n    df_ecoulement_expanded.to_csv(\"ile_de_france_ecoulement_2022-2024.csv\", index=False)\n    print(\"Data saved to ile_de_france_ecoulement_2022-2024.csv\")\nelse:\n    print(f\"Failed to fetch data: {response.status_code} - {response.text}\")\n\ndf_ecoulement_expanded[\"code_commune\"].unique()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nimport pandas as pd\n\nurl = \"https://hubeau.eaufrance.fr/api/v1/qualite_eau_potable/resultats_dis\"\n\nparams = {\n    \"size\" : 20000,\n     \"page\" : 1,\n    \"fields\": (\n        \"code_commune,nom_commune,date_prelevement,libelle_parametre,\"\n        \"resultat_numerique,libelle_unite,conclusion_conformite_prelevement\"\n    ),\n    \"code_departement\": \"75,77,78,91,92,93,94,95\",\n    \"date_min_prelevement\": \"2014-01-01\",\n    \"date_max_prelevement\": \"2024-01-01\"\n}\n\nall_data = []\n\nwhile True:\n    response = requests.get(url, params=params)\n    if response.status_code in [200, 206]:\n        response_data = response.json()\n        data = response_data.get(\"data\", [])\n        all_data.extend(data)\n        next_page = response_data.get(\"next\")\n        if not next_page:\n            break\n        params[\"page\"] += 1\n        break # only one page\n    else:\n        print(f\"Failed to fetch data on page {params['page']}: {response.status_code} - {response.text}\")\n        break\n\ndf_qualite = pd.DataFrame(all_data)\ndf_qualite = df_qualite[df_qualite[\"libelle_unite\"] != \"SANS OBJET\"]\ndf_qualite[\"conclusion_conformite_prelevement\"] = df_qualite[\"conclusion_conformite_prelevement\"].apply(\n    lambda x: 1 if \"Eau d'alimentation conforme\" in x else 0\n)\n\n\"\"\"\ndf_qualite[\"code_reseau\"] = df_qualite[\"code_reseau\"].apply(\n    lambda x: x if isinstance(x, list) else [x]\n)\ndf_qualite_expanded = df_qualite.explode(\"code_reseau\")\n\"\"\"\n\ndf_qualite_expanded = df_qualite\ndf_qualite_expanded.to_csv(\"ile_de_france_water_quality_2022-2024.csv\", index=False)\nprint(\"Data saved to ile_de_france_water_quality_2022-2024.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:48:05.22584Z","iopub.execute_input":"2024-12-03T14:48:05.226976Z","iopub.status.idle":"2024-12-03T14:48:30.15736Z","shell.execute_reply.started":"2024-12-03T14:48:05.226926Z","shell.execute_reply":"2024-12-03T14:48:30.155632Z"}},"outputs":[{"name":"stdout","text":"Data saved to ile_de_france_water_quality_2022-2024.csv\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import requests\nimport pandas as pd\nfrom io import StringIO\n\n# Base URL for the API\nurl = \"https://hubeau.eaufrance.fr/api/v1/qualite_eau_potable/resultats_dis.csv\"\n\n# Parameters for the API request\nparams = {\n    \"size\": 5000,  # Adjusted to a smaller size to comply with API limits\n    \"fields\": (\n        \"code_commune,nom_commune,date_prelevement,libelle_parametre,\"\n        \"resultat_numerique,libelle_unite,conclusion_conformite_prelevement\"\n    ),\n    \"code_departement\": \"75,77,78,91,92,93,94,95\",\n    \"date_min_prelevement\": \"2020-01-01\",\n    \"date_max_prelevement\": \"2024-01-01\",\n    \"page\": 1  # Start with the first page\n}\n\n# Headers for the request\nheaders = {\"accept\": \"text/csv\"}\n\n# Initialize an empty DataFrame to store all data\nall_data = pd.DataFrame()\n\nwhile True:\n    # Make the API call\n    response = requests.get(url, params=params, headers=headers)\n    \n    if response.status_code in [200, 206]:  # Handle both 200 and 206 status codes\n        # Debugging: Print first 500 characters of response to inspect formatting\n        print(response.text[:500])\n        \n        try:\n            # Parse the CSV response with error handling for malformed rows\n            csv_data = StringIO(response.text)\n            df_page = pd.read_csv(csv_data, on_bad_lines=\"skip\")  # Skips bad lines\n            \n            # Append the page data to the main DataFrame\n            all_data = pd.concat([all_data, df_page], ignore_index=True)\n        except Exception as e:\n            print(f\"Error processing page {params['page']}: {e}\")\n            break\n        \n        # Check if fewer rows are returned than the requested size, indicating the last page\n        if len(df_page) < params[\"size\"]:\n            break\n        \n        # Increment the page number for the next request\n        params[\"page\"] += 1\n    else:\n        print(f\"Failed to fetch data: {response.status_code} - {response.text}\")\n        break\n\n# Process the data if available\nif not all_data.empty:\n   all_data.to_csv(\"data.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:03:12.383296Z","iopub.execute_input":"2024-12-03T15:03:12.383753Z","iopub.status.idle":"2024-12-03T15:03:14.567111Z","shell.execute_reply.started":"2024-12-03T15:03:12.383713Z","shell.execute_reply":"2024-12-03T15:03:14.565742Z"}},"outputs":[{"name":"stdout","text":"\"libelle_parametre\";\"resultat_numerique\";\"libelle_unite\";\"code_commune\";\"nom_commune\";\"date_prelevement\";\"conclusion_conformite_prelevement\"\n\"Conductivit√© √† 25¬∞C\";\"552.0\";\"¬µS/cm\";\"94078\";\"VILLENEUVE-SAINT-GEORGES\";\"2023-12-29T15:55:00Z\";\"Eau d'alimentation conforme aux exigences de qualit√© en vigueur pour l'ensemble des param√®tres mesur√©s.\"\n\"Temp√©rature de l'eau\";\"11.6\";\"¬∞C\";\"94078\";\"VILLENEUVE-SAINT-GEORGES\";\"2023-12-29T15:55:00Z\";\"Eau d'alimentation conforme aux exigences de qualit√© en vigueur\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"df_qualite[\"code_commune\"].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T12:20:41.577138Z","iopub.execute_input":"2024-12-03T12:20:41.577751Z","iopub.status.idle":"2024-12-03T12:20:41.593943Z","shell.execute_reply.started":"2024-12-03T12:20:41.5777Z","shell.execute_reply":"2024-12-03T12:20:41.591583Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array(['94016', '94003', '91377', '94037', '91339', '91272', '94038',\n       '91471', '94043', '94079', '91570', '93078', '93007', '91549',\n       '94068', '77260', '94081', '91103', '94054', '93010', '77289',\n       '77514', '77445', '94041', '93027', '95018', '93070', '77296',\n       '91469', '91521', '95063', '93066', '75056', '77147', '77288',\n       '77509', '93045', '77243', '91589', '91533', '77285', '77101',\n       '77414', '93001', '93048', '77111', '77019', '77012', '77435',\n       '95572', '94074', '91390', '77359', '94058', '94044', '93073',\n       '93059', '77279', '77130', '93064', '77131', '77194', '77210',\n       '77249', '93050', '77305', '93072', '77358', '77448', '93015',\n       '95500', '77251', '77172', '93051', '92064', '77284', '77122',\n       '94046', '94002', '91345', '77108', '78640', '77083', '91156',\n       '78646', '78158', '78418', '95353', '91292', '78311', '95151',\n       '95304', '77316', '91692', '78586', '95199', '77132', '93079',\n       '78358', '78361', '91657', '77382', '93053', '78335', '95489',\n       '77054', '91687', '91174', '95014', '77118', '78536', '91573',\n       '95585', '95127', '95341', '94017', '77038', '78423', '94053',\n       '91223', '77034', '91079', '94071', '93005', '78551', '91433',\n       '78073', '78242', '94022', '94028', '91069', '78517', '91617',\n       '77068', '78516', '91112', '91201', '78165', '93008', '95541',\n       '78029', '78123', '91435', '95429', '78490', '95427', '91198',\n       '77476', '77404', '78015', '78238', '95428', '77159', '91477',\n       '91228', '95462', '78440', '95219', '77227', '95295', '78401',\n       '95203', '94018', '93032', '93014', '78528', '93046', '77310',\n       '95394', '91587', '91106', '78502', '77468', '77236', '95371',\n       '77076', '77479', '77221', '95476', '77237', '77347', '95012',\n       '78349', '91546', '77203', '77363', '95026', '77464', '77005',\n       '91421', '94076', '91027', '77061', '93031', '92024', '94042',\n       '77384', '93029', '93039', '91286', '95268', '77060', '77201'],\n      dtype=object)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"a = df_qualite_expanded[\"code_commune\"].unique()\nb = df_ecoulement_expanded[\"code_commune\"].unique()\n\ndef intersection(a, b):\n    return [ e for e in a if e in b ]\n\nprint(intersection(b, a))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T12:08:34.926866Z","iopub.execute_input":"2024-12-03T12:08:34.92734Z","iopub.status.idle":"2024-12-03T12:08:34.95177Z","shell.execute_reply.started":"2024-12-03T12:08:34.927296Z","shell.execute_reply":"2024-12-03T12:08:34.950313Z"}},"outputs":[{"name":"stdout","text":"['78536', '77060', '91573', '77384', '77076', '77131', '77363']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"df_qualite_expanded[\"code_commune\"] = df_qualite_expanded[\"code_commune\"].astype(str)\ndf_ecoulement_expanded[\"code_commune\"] = df_ecoulement_expanded[\"code_commune\"].astype(str)\n\ndf_merged = pd.merge(\n    df_qualite_expanded,\n    df_ecoulement_expanded,\n    on=\"code_commune\",\n    how=\"inner\",\n    suffixes=(\"_quality\", \"_ecoulement\")\n)\n\ndf_merged.to_csv(\"ile_de_france_merged.csv\", index=False)\nprint(\"Merged data saved to ile_de_france_merged.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T12:08:34.953228Z","iopub.execute_input":"2024-12-03T12:08:34.95365Z","iopub.status.idle":"2024-12-03T12:08:35.029256Z","shell.execute_reply.started":"2024-12-03T12:08:34.953604Z","shell.execute_reply":"2024-12-03T12:08:35.0277Z"}},"outputs":[{"name":"stdout","text":"Merged data saved to ile_de_france_merged.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import requests\nimport pandas as pd\n\nurl_contaminants = \"https://hubeau.eaufrance.fr/api/v1/surveillance_littoral/contaminants_chimiques\"\nparams_contaminants = {\n    \"format\": \"json\",\n    \"fields\": (\n        \"code_lieusurv,libelle_lieusurv,longitude,latitude,\"\n        \"date_prel,code_parametre,libelle_parametre,\"\n        \"resultat_analyse,libelle_unite_resultat\"\n    ),\n    \"date_min_prel\": \"2014-01-01T00:00:00\",\n    \"date_max_prel\": \"2024-12-31T23:59:59\",\n    \"size\": 500,\n    \"page\": 1,\n}\n\nall_contaminants_data = []\ncurrent_page = 1\n\nwhile True:\n    response_contaminants = requests.get(url_contaminants, params=params_contaminants)\n    if response_contaminants.status_code in [200, 206]:\n        response_data = response_contaminants.json()\n        data_contaminants = response_data.get(\"data\", [])\n        \n        if not data_contaminants:\n            break\n        \n        all_contaminants_data.extend(data_contaminants)\n        \n        next_page = response_data.get(\"next\")\n        if not next_page or current_page * params_contaminants[\"size\"] >= 20000:\n            break\n        \n        params_contaminants[\"page\"] += 1\n        current_page += 1\n    else:\n        break\n\nif all_contaminants_data:\n    df_contaminants = pd.DataFrame(all_contaminants_data)\n    selected_columns = [\n        \"code_lieusurv\", \"libelle_lieusurv\", \"longitude\", \"latitude\", \n        \"date_prel\", \"code_parametre\", \n        \"libelle_parametre\", \"resultat_analyse\", \"libelle_unite_resultat\"\n    ]\n    df_contaminants_filtered = df_contaminants[selected_columns]\n\n    df_contaminants_expanded = df_contaminants_filtered\n    df_contaminants_expanded.to_csv(\"littoral_contaminants_2022-2024.csv\", index=False)\n    print(\"Data saved to littoral_contaminants_2022-2024.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T12:21:02.636291Z","iopub.execute_input":"2024-12-03T12:21:02.636973Z","iopub.status.idle":"2024-12-03T12:21:41.959321Z","shell.execute_reply.started":"2024-12-03T12:21:02.636899Z","shell.execute_reply":"2024-12-03T12:21:41.957733Z"}},"outputs":[{"name":"stdout","text":"Data saved to littoral_contaminants_2022-2024.csv\n","output_type":"stream"}],"execution_count":16}]}