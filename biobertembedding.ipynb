{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lukalafaye/biobertembedding?scriptVersionId=201553954\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!git clone https://github.com/ariellubonja/biobert_embedding","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:43:50.612714Z","iopub.execute_input":"2024-07-08T19:43:50.61375Z","iopub.status.idle":"2024-07-08T19:43:52.434096Z","shell.execute_reply.started":"2024-07-08T19:43:50.613704Z","shell.execute_reply":"2024-07-08T19:43:52.432789Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'biobert_embedding'...\nremote: Enumerating objects: 79, done.\u001b[K\nremote: Counting objects: 100% (79/79), done.\u001b[K\nremote: Compressing objects: 100% (63/63), done.\u001b[K\nremote: Total 79 (delta 39), reused 40 (delta 14), pack-reused 0\u001b[K\nUnpacking objects: 100% (79/79), 20.62 KiB | 754.00 KiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls biobert_embedding","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:46:49.611929Z","iopub.execute_input":"2024-07-08T19:46:49.612368Z","iopub.status.idle":"2024-07-08T19:46:50.68425Z","shell.execute_reply.started":"2024-07-08T19:46:49.612312Z","shell.execute_reply":"2024-07-08T19:46:50.682952Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"LICENSE  README.md  biobert_embedding  setup.py\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/working/biobert_embedding\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:48:38.895252Z","iopub.execute_input":"2024-07-08T19:48:38.895676Z","iopub.status.idle":"2024-07-08T19:48:38.90072Z","shell.execute_reply.started":"2024-07-08T19:48:38.895643Z","shell.execute_reply":"2024-07-08T19:48:38.899668Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!pip install .","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:49:22.69133Z","iopub.execute_input":"2024-07-08T19:49:22.691737Z","iopub.status.idle":"2024-07-08T19:51:54.470923Z","shell.execute_reply.started":"2024-07-08T19:49:22.691702Z","shell.execute_reply":"2024-07-08T19:51:54.469058Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Processing /kaggle/working/biobert_embedding\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting torch==2.1.2 (from biobert-embedding==0.1.4)\n  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\nCollecting pytorch-pretrained-bert==0.6.2 (from biobert-embedding==0.1.4)\n  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl.metadata (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (1.26.4)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (1.26.100)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (4.66.4)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (2023.12.25)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->biobert-embedding==0.1.4) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->biobert-embedding==0.1.4) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->biobert-embedding==0.1.4) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->biobert-embedding==0.1.4) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->biobert-embedding==0.1.4) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->biobert-embedding==0.1.4) (2024.3.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.1.0 (from torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->biobert-embedding==0.1.4)\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (0.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.2->biobert-embedding==0.1.4) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2->biobert-embedding==0.1.4) (1.3.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.4) (1.16.0)\nDownloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: biobert-embedding\n  Building wheel for biobert-embedding (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for biobert-embedding: filename=biobert_embedding-0.1.4-py3-none-any.whl size=6174 sha256=f39b45228cafc695cec0cc3ee9875a232272d93ab635a2631e0e933dbbd84e02\n  Stored in directory: /tmp/pip-ephem-wheel-cache-xq4d1w1l/wheels/83/c9/23/89dd7d5b062adcff3b787524d3551252100a221c5162cfcfda\nSuccessfully built biobert-embedding\nInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, nvidia-cusolver-cu12, torch, pytorch-pretrained-bert, biobert-embedding\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.106\n    Uninstalling botocore-1.34.106:\n      Successfully uninstalled botocore-1.34.106\n  Attempting uninstall: torch\n    Found existing installation: torch 1.13.1\n    Uninstalling torch-1.13.1:\n      Successfully uninstalled torch-1.13.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.13.0 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\naiobotocore 2.13.0 requires botocore<1.34.107,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\ntorchaudio 0.13.1 requires torch==1.13.1, but you have torch 2.1.2 which is incompatible.\ntorchdata 0.5.1 requires torch==1.13.1, but you have torch 2.1.2 which is incompatible.\ntorchtext 0.14.1 requires torch==1.13.1, but you have torch 2.1.2 which is incompatible.\ntorchvision 0.14.1 requires torch==1.13.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed biobert-embedding-0.1.4 botocore-1.29.165 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pytorch-pretrained-bert-0.6.2 torch-2.1.2 triton-2.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from biobert_embedding.embedding import BiobertEmbedding\n\n## Example 1\ntext = \"Breast cancers with HER2 amplification have a higher risk of CNS metastasis and poorer prognosis.\"\\\n\n# Class Initialization (You can set default 'model_path=None' as your finetuned BERT model path while Initialization)\nbiobert = BiobertEmbedding()\n\nword_embeddings = biobert.word_vector(text)\nsentence_embedding = biobert.sentence_vector(text)\n\nprint(\"Text Tokens: \", biobert.tokens)\n# Text Tokens:  ['breast', 'cancers', 'with', 'her2', 'amplification', 'have', 'a', 'higher', 'risk', 'of', 'cns', 'metastasis', 'and', 'poorer', 'prognosis', '.']\n\nprint ('Shape of Word Embeddings: %d x %d' % (len(word_embeddings), len(word_embeddings[0])))\n# Shape of Word Embeddings: 16 x 768\n\nprint(\"Shape of Sentence Embedding = \",len(sentence_embedding))\n# Shape of Sentence Embedding =  768\n\n## Example 2\nsentence_vector1 = biobert.sentence_vector('Breast cancers with HER2 amplification have a higher risk of CNS metastasis and poorer prognosis.')\nsentence_vector2 = biobert.sentence_vector('Breast cancers with HER2 amplification are more aggressive, have a higher risk of CNS metastasis, and poorer prognosis.')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T20:00:47.219548Z","iopub.execute_input":"2024-07-08T20:00:47.220364Z","iopub.status.idle":"2024-07-08T20:00:50.365972Z","shell.execute_reply.started":"2024-07-08T20:00:47.220303Z","shell.execute_reply":"2024-07-08T20:00:50.364862Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Using existing models/pytorch_model.bin\nUsing existing models/config.json\nUsing existing models/vocab.txt\nText Tokens:  ['breast', 'cancers', 'with', 'her2', 'amplification', 'have', 'a', 'higher', 'risk', 'of', 'cns', 'metastasis', 'and', 'poorer', 'prognosis', '.']\nShape of Word Embeddings: 16 x 768\nShape of Sentence Embedding =  768\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy import spatial","metadata":{"execution":{"iopub.status.busy":"2024-07-08T20:02:26.898708Z","iopub.execute_input":"2024-07-08T20:02:26.899127Z","iopub.status.idle":"2024-07-08T20:02:26.904656Z","shell.execute_reply.started":"2024-07-08T20:02:26.899095Z","shell.execute_reply":"2024-07-08T20:02:26.903384Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"cosine_sim = 1 - spatial.distance.cosine(sentence_vector1, sentence_vector2)\nprint('cosine similarity:', cosine_sim)\n#cosine similarity: 0.992756187915802","metadata":{"execution":{"iopub.status.busy":"2024-07-08T20:02:24.783191Z","iopub.execute_input":"2024-07-08T20:02:24.783564Z","iopub.status.idle":"2024-07-08T20:02:24.790986Z","shell.execute_reply.started":"2024-07-08T20:02:24.783533Z","shell.execute_reply":"2024-07-08T20:02:24.789849Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"cosine similarity: 0.9927561283111572\n","output_type":"stream"}]}]}