{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9644358,"sourceType":"datasetVersion","datasetId":5887736},{"sourceId":145569,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":123427,"modelId":139891}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lukalafaye/gan-mnist-dslab2?scriptVersionId=205561053\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nos.environ['PYTHON_PATH'] = \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2024-11-01T14:59:10.488361Z","iopub.execute_input":"2024-11-01T14:59:10.488643Z","iopub.status.idle":"2024-11-01T14:59:10.498131Z","shell.execute_reply.started":"2024-11-01T14:59:10.48861Z","shell.execute_reply":"2024-11-01T14:59:10.497291Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\n\n# Specify the device (GPU or CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef D_train(x, G, D, D_optimizer, criterion):\n    #======================= Train the discriminator =======================#\n    D.zero_grad()\n\n    # Train discriminator on real data\n    x_real = x.to(device)\n    y_real = torch.ones(x_real.shape[0], 1, device=device)\n\n    D_output = D(x_real)\n    D_real_loss = criterion(D_output, y_real)\n    D_real_score = D_output\n\n    # Train discriminator on fake data\n    z = torch.randn(x_real.shape[0], 100, device=device)  # Latent vector\n    x_fake = G(z)\n    y_fake = torch.zeros(x_real.shape[0], 1, device=device)\n\n    D_output = D(x_fake)\n\n    D_fake_loss = criterion(D_output, y_fake)\n    D_fake_score = D_output\n\n    # Gradient backpropagation & optimize ONLY D's parameters\n    D_loss = D_real_loss + D_fake_loss\n    D_loss.backward()\n    D_optimizer.step()\n        \n    return D_loss.item(), D_real_score, D_fake_score  # Return scores for analysis\n\n\ndef G_train(x, G, D, G_optimizer, criterion):\n    #======================= Train the generator =======================#\n    G.zero_grad()\n\n    z = torch.randn(x.shape[0], 100, device=device)  # Latent vector\n    y = torch.ones(z.shape[0], 1, device=device)  # Target for generator\n\n    G_output = G(z)\n    D_output = D(G_output)\n    G_loss = criterion(D_output, y)\n\n    # Gradient backpropagation & optimize ONLY G's parameters\n    G_loss.backward()\n    G_optimizer.step()\n        \n    return G_loss.item(), D_output  # Return D_output for analysis\n\n\ndef save_models(G, D, folder):\n    os.makedirs(folder, exist_ok=True)  # Ensure the folder exists\n    torch.save(G.state_dict(), os.path.join(folder, 'G.pth'))\n    torch.save(D.state_dict(), os.path.join(folder, 'D.pth'))\n\n\ndef load_model(model, folder, is_generator=True):\n    model_type = 'G' if is_generator else 'D'\n    ckpt = torch.load(os.path.join(folder, f'{model_type}.pth'), map_location=device)  # Load model to the correct device\n    model.load_state_dict({k.replace('module.', ''): v for k, v in ckpt.items()})\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-01T14:59:48.820722Z","iopub.execute_input":"2024-11-01T14:59:48.821103Z","iopub.status.idle":"2024-11-01T14:59:51.978184Z","shell.execute_reply.started":"2024-11-01T14:59:48.821063Z","shell.execute_reply":"2024-11-01T14:59:51.977232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Generator(nn.Module):\n    def __init__(self, g_output_dim):\n        super(Generator, self).__init__()       \n        self.fc1 = nn.Linear(100, 256)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features * 2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features * 2)\n        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n\n    def forward(self, x): \n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        return torch.tanh(self.fc4(x))\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, d_input_dim):\n        super(SanDiscriminator, self).__init__()\n        self.fc1 = nn.Linear(d_input_dim, 1024)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features // 2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features // 2)\n        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n        \n        # Self-attention inspired parameters\n        self.attention_weights = nn.Parameter(torch.randn(1, self.fc3.out_features))\n\n    def forward(self, x):\n        # Extract features through fully connected layers\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        x = torch.sigmoid(self.fc4(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T14:59:59.733258Z","iopub.execute_input":"2024-11-01T14:59:59.733961Z","iopub.status.idle":"2024-11-01T14:59:59.746408Z","shell.execute_reply.started":"2024-11-01T14:59:59.733922Z","shell.execute_reply":"2024-11-01T14:59:59.745531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch \nimport torchvision\nimport os\nimport argparse","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-01T15:00:05.560833Z","iopub.execute_input":"2024-11-01T15:00:05.561692Z","iopub.status.idle":"2024-11-01T15:00:06.676421Z","shell.execute_reply.started":"2024-11-01T15:00:05.56163Z","shell.execute_reply":"2024-11-01T15:00:06.675473Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args = argparse.Namespace(batch_size=20)  # Set default value\n\nprint('Model Loading...')\n# Model Pipeline\nmnist_dim = 784\n\nmodel = Generator(g_output_dim = mnist_dim).cuda()\nmodel = load_model(model, '/kaggle/input/g/pytorch/v2/1/')\nmodel = torch.nn.DataParallel(model).cuda()\nmodel.eval()\n\nprint('Model loaded.')\n\n\nprint('Start Generating')\nos.makedirs('samples', exist_ok=True)\n\nimage_paths = []\n\nn_samples = 0\nwith torch.no_grad():\n    while n_samples<10000:\n        z = torch.randn(args.batch_size, 100).cuda()\n        x = model(z)\n        x = x.reshape(args.batch_size, 28, 28)\n        for k in range(x.shape[0]):\n            if n_samples<10000:\n                image_path = os.path.join('samples', f'{n_samples}.png')\n                torchvision.utils.save_image(x[k:k+1], image_path)         \n                image_paths.append(image_path)  # Store image path\n                n_samples += 1","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:09.451836Z","iopub.execute_input":"2024-11-01T15:00:09.452635Z","iopub.status.idle":"2024-11-01T15:00:16.476086Z","shell.execute_reply.started":"2024-11-01T15:00:09.452596Z","shell.execute_reply":"2024-11-01T15:00:16.475119Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import display, Image\n\nfor img_path in image_paths[:50]:  # Slice to get only the first 10 images\n    display(Image(filename=img_path))","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:18.957416Z","iopub.execute_input":"2024-11-01T15:00:18.958387Z","iopub.status.idle":"2024-11-01T15:00:19.056568Z","shell.execute_reply.started":"2024-11-01T15:00:18.958332Z","shell.execute_reply":"2024-11-01T15:00:19.055706Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:22.633304Z","iopub.execute_input":"2024-11-01T15:00:22.633909Z","iopub.status.idle":"2024-11-01T15:00:22.63818Z","shell.execute_reply.started":"2024-11-01T15:00:22.633869Z","shell.execute_reply":"2024-11-01T15:00:22.637156Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\nfrom tqdm import trange\nimport argparse\nfrom torchvision import datasets, transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom model import Generator, Discriminator\nfrom utils import D_train, G_train, save_models\nfrom IPython.display import display \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nparser = argparse.ArgumentParser(description='Train Normalizing Flow.')\nparser.add_argument(\"--epochs\", type=int, default=400, help=\"Number of epochs for training.\")\nparser.add_argument(\"--lr\", type=float, default=0.0001, help=\"The learning rate to use for training.\")\nparser.add_argument(\"--batch_size\", type=int, default=1024, help=\"Size of mini-batches for SGD\")\nargs = parser.parse_args(args=[])\n\nos.makedirs('checkpoints', exist_ok=True)\nos.makedirs('data', exist_ok=True)\n\nprint('Dataset loading...')\ntransform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\ntrain_dataset = datasets.MNIST(root='data/MNIST/', train=True, transform=transform, download=True)\ntest_dataset = datasets.MNIST(root='data/MNIST/', train=False, transform=transform, download=False)\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                           batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n                                          batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True)\nprint('Dataset Loaded.')\n\nprint('Model Loading...')\nmnist_dim = 784\nG = torch.nn.DataParallel(Generator(g_output_dim=mnist_dim)).to(device)\nD = torch.nn.DataParallel(Discriminator(mnist_dim)).to(device)\nprint('Model loaded.')\n\ncriterion = nn.BCELoss().to(device)\nG_optimizer = optim.Adam(G.parameters(), lr=args.lr)\nD_optimizer = optim.Adam(D.parameters(), lr=args.lr)\n\nprint('Start Training:')\n\ndef plot_generated_images(generator, epoch, num_images=20):\n    \"\"\"Function to plot and display generated images from the generator.\"\"\"\n    generator.eval()\n    with torch.no_grad():\n        noise = torch.randn(num_images, 100).to(device)\n        generated_images = generator(noise)\n        generated_images = generated_images.view(-1, 1, 28, 28).cpu()\n\n        # Create two rows of 10 images\n        fig, axes = plt.subplots(2, 10, figsize=(15, 6))\n        axes = axes.flatten()  # Flatten the axes array for easy iteration\n        for ax, img in zip(axes, generated_images):\n            ax.imshow(img.squeeze(), cmap='gray')\n            ax.axis('off')\n        plt.tight_layout()\n        plt.show()\n\ndef plot_losses(G_losses, D_losses):\n    \"\"\"Function to plot the losses over epochs.\"\"\"\n    plt.figure(figsize=(10, 5))\n    plt.plot(G_losses, label=\"Generator Loss\")\n    plt.plot(D_losses, label=\"Discriminator Loss\")\n    plt.title(\"Generator and Discriminator Losses Over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\n\n# Initialize lists to store the losses\nG_losses = []\nD_losses = []\n\nn_epoch = args.epochs\nfor epoch in trange(1, n_epoch + 1, leave=True):\n    print(epoch)\n    G_loss_epoch = 0\n    D_loss_epoch = 0\n    \n    for batch_idx, (x, _) in enumerate(train_loader):\n        x = x.view(-1, mnist_dim).to(device)\n        \n        D_loss, _, _ = D_train(x, G, D, D_optimizer, criterion)  # Capture only the first return value\n        G_loss, _ = G_train(x, G, D, G_optimizer, criterion)  # Capture only the first return value\n\n        # Accumulate the losses for the current epoch\n        D_loss_epoch += D_loss\n        G_loss_epoch += G_loss\n\n    # Store the average loss per epoch\n    D_losses.append(D_loss_epoch / len(train_loader))\n    G_losses.append(G_loss_epoch / len(train_loader))\n\n    print(f\"Epoch [{epoch}/{n_epoch}], D Loss: {D_losses[-1]:.4f}, G Loss: {G_losses[-1]:.4f}\")\n\n    # Save models and generate images every 10 epochs\n    if epoch % 10 == 0:\n        save_models(G, D, 'checkpoints')\n        plot_generated_images(G, epoch)\n\n# After training, plot the losses\nplot_losses(G_losses, D_losses)\n\nprint('Training done')","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:29.956356Z","iopub.execute_input":"2024-11-01T15:00:29.9571Z","iopub.status.idle":"2024-11-01T15:39:02.826613Z","shell.execute_reply.started":"2024-11-01T15:00:29.957039Z","shell.execute_reply":"2024-11-01T15:39:02.825489Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls checkpoints","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:54:31.632527Z","iopub.execute_input":"2024-11-01T15:54:31.633368Z","iopub.status.idle":"2024-11-01T15:54:32.641225Z","shell.execute_reply.started":"2024-11-01T15:54:31.633312Z","shell.execute_reply":"2024-11-01T15:54:32.640045Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_models(generator, discriminator, epoch, g_losses, d_losses, path='checkpoints'):\n    checkpoint = {\n        'epoch': epoch,\n        'G_state_dict': generator.state_dict(),\n        'D_state_dict': discriminator.state_dict(),\n        'G_optimizer_state_dict': G_optimizer.state_dict(),\n        'D_optimizer_state_dict': D_optimizer.state_dict(),\n        'G_losses': g_losses,\n        'D_losses': d_losses\n    }\n    torch.save(checkpoint, os.path.join(path, 'model_checkpoint.pth'))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:54:33.398018Z","iopub.execute_input":"2024-11-01T15:54:33.398465Z","iopub.status.idle":"2024-11-01T15:54:33.405294Z","shell.execute_reply.started":"2024-11-01T15:54:33.398423Z","shell.execute_reply":"2024-11-01T15:54:33.40421Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_models(generator, discriminator, epoch, g_losses, d_losses)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:54:35.252957Z","iopub.execute_input":"2024-11-01T15:54:35.253359Z","iopub.status.idle":"2024-11-01T15:54:35.580072Z","shell.execute_reply.started":"2024-11-01T15:54:35.25332Z","shell.execute_reply":"2024-11-01T15:54:35.578907Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_checkpoint(generator, discriminator, g_optimizer, d_optimizer, path='checkpoints/model_checkpoint.pth'):\n    checkpoint = torch.load(path)\n    generator.load_state_dict(checkpoint['G_state_dict'])\n    discriminator.load_state_dict(checkpoint['D_state_dict'])\n    g_optimizer.load_state_dict(checkpoint['G_optimizer_state_dict'])\n    d_optimizer.load_state_dict(checkpoint['D_optimizer_state_dict'])\n    start_epoch = checkpoint['epoch'] + 1\n    g_losses = checkpoint['G_losses']\n    d_losses = checkpoint['D_losses']\n    return start_epoch, g_losses, d_losses\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.396905Z","iopub.status.idle":"2024-10-27T17:02:17.397277Z","shell.execute_reply.started":"2024-10-27T17:02:17.397077Z","shell.execute_reply":"2024-10-27T17:02:17.397114Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if a checkpoint exists to resume from\ncheckpoint_path = 'checkpoints/model_checkpoint.pth'\nif os.path.exists(checkpoint_path):\n    print(\"Loading checkpoint...\")\n    start_epoch, G_losses, D_losses = load_checkpoint(G, D, G_optimizer, D_optimizer, checkpoint_path)\n    print(f\"Resuming from epoch {start_epoch}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.398682Z","iopub.status.idle":"2024-10-27T17:02:17.399054Z","shell.execute_reply.started":"2024-10-27T17:02:17.398878Z","shell.execute_reply":"2024-10-27T17:02:17.398898Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_epoch=30\nfor epoch in trange(1, n_epoch + 1, leave=True):\n    print(epoch)\n    G_loss_epoch = 0\n    D_loss_epoch = 0\n    \n    for batch_idx, (x, _) in enumerate(train_loader):\n        x = x.view(-1, mnist_dim).to(device)\n        \n        D_loss, _, _ = D_train(x, G, D, D_optimizer, criterion)  # Capture only the first return value\n        G_loss, _ = G_train(x, G, D, G_optimizer, criterion)  # Capture only the first return value\n\n        # Accumulate the losses for the current epoch\n        D_loss_epoch += D_loss\n        G_loss_epoch += G_loss\n\n    # Store the average loss per epoch\n    D_losses.append(D_loss_epoch / len(train_loader))\n    G_losses.append(G_loss_epoch / len(train_loader))\n\n    print(f\"Epoch [{epoch}/{n_epoch}], D Loss: {D_losses[-1]:.4f}, G Loss: {G_losses[-1]:.4f}\")\n\n    # Save models and generate images every 10 epochs\n    if epoch % 10 == 0:\n        save_models(G, D, 'checkpoints')\n        plot_generated_images(G, epoch)\n\n# After training, plot the losses\nplot_losses(G_losses, D_losses)\n\nprint('Training done')","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.400518Z","iopub.status.idle":"2024-10-27T17:02:17.400886Z","shell.execute_reply.started":"2024-10-27T17:02:17.400699Z","shell.execute_reply":"2024-10-27T17:02:17.400724Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(G.state_dict(), 'generator2.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.402246Z","iopub.status.idle":"2024-10-27T17:02:17.402704Z","shell.execute_reply.started":"2024-10-27T17:02:17.402464Z","shell.execute_reply":"2024-10-27T17:02:17.402488Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch torchvision tqdm matplotlib","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Generator(nn.Module):\n    def __init__(self, g_output_dim=784, dim_latent=100):\n        super(Generator, self).__init__()\n        self.fc1 = nn.Linear(100, 256)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        return torch.tanh(self.fc4(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:38:17.7936Z","iopub.execute_input":"2024-11-06T10:38:17.793895Z","iopub.status.idle":"2024-11-06T10:38:23.544643Z","shell.execute_reply.started":"2024-11-06T10:38:17.793863Z","shell.execute_reply":"2024-11-06T10:38:23.543506Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class BaseDiscriminator(nn.Module):\n    def __init__(self, input_dim=784):\n        super(BaseDiscriminator, self).__init__()\n        # Fully connected layers replacing convolutional layers\n        self.fc1 = nn.Linear(input_dim, 1024)  # input_dim should match the generator's output dimension\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 256)\n        # Final classification layer with spectral normalization\n        self.fc4 = nn.utils.spectral_norm(nn.Linear(256, 1))\n        \n        # Class embedding weights\n        self.use_class = num_class > 0\n\n        # Class-specific weights for feature scaling\n        self.fc_w = nn.Parameter(torch.randn(1, 256))\n\n    def forward(self, x):        \n        # Pass input through the fully connected layers\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        h_feature = F.leaky_relu(self.fc3(x), 0.2)\n        h_feature = torch.flatten(h_feature, start_dim=1)\n        weights = self.fc_w\n        out = (h_feature * weights).sum(dim=1)\n        return out\n\n# Modified Discriminator Architecture\nclass SanDiscriminator(BaseDiscriminator):\n    def __init__(self, num_class=10):\n        super(SanDiscriminator, self).__init__(num_class)\n\n    def forward(self, x, class_ids, flg_train: bool):\n        h_feature = self.h_function(x)\n        h_feature = torch.flatten(h_feature, start_dim=1)\n        weights = self.fc_w[class_ids] if self.use_class else self.fc_w\n        direction = F.normalize(weights, dim=1) # Normalize the last layer\n        scale = torch.norm(weights, dim=1).unsqueeze(1)\n        h_feature = h_feature * scale # For keep the scale\n        if flg_train: # for discriminator training\n            out_fun = (h_feature * direction.detach()).sum(dim=1)\n            out_dir = (h_feature.detach() * direction).sum(dim=1)\n            out = dict(fun=out_fun, dir=out_dir)\n        else: # for generator training or inference\n            out = (h_feature * direction).sum(dim=1)\n\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:46:19.822995Z","iopub.execute_input":"2024-11-06T10:46:19.82353Z","iopub.status.idle":"2024-11-06T10:46:19.842097Z","shell.execute_reply.started":"2024-11-06T10:46:19.823464Z","shell.execute_reply":"2024-11-06T10:46:19.841018Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import argparse\nimport json\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport tqdm\n\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:46:21.304001Z","iopub.execute_input":"2024-11-06T10:46:21.3045Z","iopub.status.idle":"2024-11-06T10:46:21.312555Z","shell.execute_reply.started":"2024-11-06T10:46:21.304447Z","shell.execute_reply":"2024-11-06T10:46:21.311297Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import os\nimport json\n\n# Define folder paths\nmnist_folder = './data/MNIST'\nlogs_folder = './logs'\nparams_path = './hparams/params.json'\n\n# Create folders if they don't exist\nos.makedirs(mnist_folder, exist_ok=True)\nos.makedirs(logs_folder, exist_ok=True)\nos.makedirs(os.path.dirname(params_path), exist_ok=True)\n\n# Define the parameters for params.json\nparams = {\n    \"dim_latent\": 100,\n    \"batch_size\": 128,\n    \"learning_rate\": 0.001,\n    \"beta_1\": 0.0,\n    \"beta_2\": 0.99,\n    \"num_epochs\": 2\n}\n\n# Write parameters to params.json\nwith open(params_path, 'w') as f:\n    json.dump(params, f, indent=4)\n\nprint(f\"Created folders '{mnist_folder}' and '{logs_folder}', and saved parameters to '{params_path}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:46:22.122406Z","iopub.execute_input":"2024-11-06T10:46:22.122792Z","iopub.status.idle":"2024-11-06T10:46:22.131825Z","shell.execute_reply.started":"2024-11-06T10:46:22.122755Z","shell.execute_reply":"2024-11-06T10:46:22.130843Z"}},"outputs":[{"name":"stdout","text":"Created folders './data/MNIST' and './logs', and saved parameters to './hparams/params.json'.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"default_args = {\n    \"datadir\": \"./data/MNIST\",\n    \"params\": \"./hparams/params.json\",\n    \"model\": \"gan\",\n    \"enable_class\": False,\n    \"logdir\": \"./logs\",\n    \"device\": 0\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:38:26.205343Z","iopub.execute_input":"2024-11-06T10:38:26.206001Z","iopub.status.idle":"2024-11-06T10:38:26.213723Z","shell.execute_reply.started":"2024-11-06T10:38:26.205956Z","shell.execute_reply":"2024-11-06T10:38:26.212842Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from argparse import Namespace\nargs = Namespace(**default_args)\n\nprint(args.datadir)        # Access './data/MNIST'\nprint(args.params)         # Access './hparams/params.json'\nprint(args.model)          # Access 'gan'\nprint(args.enable_class)   # Access False\nprint(args.logdir)         # Access './logs'\nprint(args.device)         # Access 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:46:23.529017Z","iopub.execute_input":"2024-11-06T10:46:23.529745Z","iopub.status.idle":"2024-11-06T10:46:23.535732Z","shell.execute_reply.started":"2024-11-06T10:46:23.529706Z","shell.execute_reply":"2024-11-06T10:46:23.534638Z"}},"outputs":[{"name":"stdout","text":"./data/MNIST\n./hparams/params.json\ngan\nFalse\n./logs\n0\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Train functions\n\ndef update_discriminator(x, discriminator, generator, optimizer, params):\n    bs = x.size(0)\n    device = x.device\n\n    optimizer.zero_grad()\n\n    # for data (ground-truth) distribution\n    disc_real = discriminator(x)\n    loss_real = eval('compute_loss_'+args.model)(disc_real, loss_type='real')\n\n    # for generator distribution\n    latent = torch.randn(bs, params[\"dim_latent\"], device=device)\n    img_fake = generator(latent)\n    disc_fake = discriminator(img_fake.detach())\n    loss_fake = eval('compute_loss_'+args.model)(disc_fake, loss_type='fake')\n\n\n    loss_d = loss_real + loss_fake\n    loss_d.backward()\n    optimizer.step()\n\n\ndef update_generator(num_class, discriminator, generator, optimizer, params, device):\n    optimizer.zero_grad()\n\n    bs = params['batch_size']\n    latent = torch.randn(bs, params[\"dim_latent\"], device=device)\n\n    batch_fake = generator(latent)\n\n    disc_gen = discriminator(batch_fake)\n    loss_g = - disc_gen.mean()\n    loss_g.backward()\n    optimizer.step()\n\n\ndef compute_loss_gan(disc, loss_type):\n    assert (loss_type in ['real', 'fake'])\n    if 'real' == loss_type:\n        loss = (1. - disc).relu().mean() # Hinge loss\n    else: # 'fake' == loss_type\n        loss = (1. + disc).relu().mean() # Hinge loss\n\n    return loss\n\n\ndef compute_loss_san(disc, loss_type):\n    assert (loss_type in ['real', 'fake'])\n    if 'real' == loss_type:\n        loss_fun = (1. - disc['fun']).relu().mean() # Hinge loss for function h\n        loss_dir = - disc['dir'].mean() # Wasserstein loss for omega\n    else: # 'fake' == loss_type\n        loss_fun = (1. + disc['fun']).relu().mean() # Hinge loss for function h\n        loss_dir = disc['dir'].mean() # Wasserstein loss for omega\n    loss = loss_fun + loss_dir\n\n    return loss\n\n\ndef save_images(imgs, idx, dirname='test'):\n    import numpy as np\n    if imgs.shape[1] == 1:\n        imgs = np.repeat(imgs, 3, axis=1)\n    fig = plt.figure(figsize=(10, 10))\n    gs = gridspec.GridSpec(10, 10)\n    gs.update(wspace=0.05, hspace=0.05)\n    for i, sample in enumerate(imgs):\n        ax = plt.subplot(gs[i])\n        plt.axis('off')\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        ax.set_aspect('equal')\n        plt.imshow(sample.transpose((1,2,0)))\n\n    if not os.path.exists('out/{}/'.format(dirname)):\n        os.makedirs('out/{}/'.format(dirname))\n    plt.savefig('out/{0}/{1}.png'.format(dirname, str(idx).zfill(3)), bbox_inches=\"tight\")\n    plt.close(fig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:48:07.413265Z","iopub.execute_input":"2024-11-06T10:48:07.414146Z","iopub.status.idle":"2024-11-06T10:48:07.432086Z","shell.execute_reply.started":"2024-11-06T10:48:07.414099Z","shell.execute_reply":"2024-11-06T10:48:07.43111Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"device = f'cuda:{args.device}' if args.device is not None else 'cpu'\nmodel_name = args.model\nif not model_name in ['gan', 'san']:\n    raise RuntimeError(\"A model name have to be 'gan' or 'san'.\")\n    \nexperiment_name = model_name + \"_cond\" if args.enable_class else model_name\n\ntransform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\n# dataloading\nnum_class = 10\ntrain_dataset = datasets.MNIST(root=args.datadir, transform=transform, train=True, download=True)\ntrain_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], num_workers=4,\n                          pin_memory=True, persistent_workers=True, shuffle=True)\n\ntest_dataset = datasets.MNIST(root=args.datadir, transform=transform, train=False, download=True)\ntest_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], num_workers=4,\n                         pin_memory=True, persistent_workers=True, shuffle=False)\n\n# model\ngenerator = Generator(g_output_dim=784)\n\nif 'gan' == args.model:\n    discriminator = BaseDiscriminator(input_dim=784)\n    #discriminator = BaseDiscriminator(num_class=num_class if use_class else 0)\nelse: # 'san' == args.model\n    discriminator = SanDiscriminator(num_class=num_class if use_class else 0)\ngenerator = generator.to(device)\ndiscriminator = discriminator.to(device)\n\n# optimizer\nbetas = (params[\"beta_1\"], params[\"beta_2\"])\noptimizer_G = optim.Adam(generator.parameters(), lr=params[\"learning_rate\"], betas=betas)\noptimizer_D = optim.Adam(discriminator.parameters(), lr=params[\"learning_rate\"], betas=betas)\n\nckpt_dir = f'{args.logdir}/{experiment_name}/'\nif not os.path.exists(args.logdir):\n    os.mkdir(args.logdir)\nif not os.path.exists(ckpt_dir):\n    os.mkdir(ckpt_dir)\n\nsteps_per_epoch = len(train_loader)\n\nmsg = [\"\\t{0}: {1}\".format(key, val) for key, val in params.items()]\nprint(\"hyperparameters: \\n\" + \"\\n\".join(msg))\n\n# eval initial states\nnum_samples_per_class = 10\nwith torch.no_grad():\n    latent = torch.randn(num_samples_per_class * num_class, params[\"dim_latent\"]).cuda()\n    imgs_fake = generator(latent)\n\n# main training loop\nfor n in range(params[\"num_epochs\"]):\n    loader = iter(train_loader)\n\n    print(\"epoch: {0}/{1}\".format(n + 1, params[\"num_epochs\"]))\n    for i in tqdm.trange(steps_per_epoch):\n        x, class_ids = next(loader)\n        x = x.to(device)\n        x = x.view(x.size(0), -1)\n\n        update_discriminator(x, discriminator, generator, optimizer_D, params)\n        update_generator(num_class, discriminator, generator, optimizer_G, params, device)\n\n    torch.save(generator.state_dict(), ckpt_dir + \"g.\" + str(n) + \".tmp\")\n    torch.save(discriminator.state_dict(), ckpt_dir + \"d.\" + str(n) + \".tmp\")\n\n    # eval\n    with torch.no_grad():\n        latent = torch.randn(num_samples_per_class * num_class, params[\"dim_latent\"]).cuda()\n        imgs_fake = generator(latent).cpu().data.numpy()\n        save_images(imgs_fake, n, dirname=experiment_name)\n\ntorch.save(generator.state_dict(), ckpt_dir + \"generator.pt\")\ntorch.save(discriminator.state_dict(), ckpt_dir + \"discriminator.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T11:02:54.293135Z","iopub.execute_input":"2024-11-06T11:02:54.294143Z","iopub.status.idle":"2024-11-06T11:03:03.391109Z","shell.execute_reply.started":"2024-11-06T11:02:54.294093Z","shell.execute_reply":"2024-11-06T11:03:03.389346Z"}},"outputs":[{"name":"stdout","text":"hyperparameters: \n\tdim_latent: 100\n\tbatch_size: 128\n\tlearning_rate: 0.001\n\tbeta_1: 0.0\n\tbeta_2: 0.99\n\tnum_epochs: 2\nepoch: 1/2\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/469 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 8/469 [00:01<00:44, 10.36it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 20/469 [00:01<00:17, 25.14it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 39/469 [00:01<00:09, 44.71it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 52/469 [00:01<00:08, 51.88it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 59/469 [00:01<00:07, 56.21it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 74/469 [00:02<00:06, 62.08it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 88/469 [00:02<00:06, 59.44it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 102/469 [00:02<00:06, 60.34it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▍       | 117/469 [00:02<00:05, 62.15it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 131/469 [00:03<00:05, 64.84it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 138/469 [00:03<00:05, 62.50it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 152/469 [00:03<00:05, 62.12it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 167/469 [00:03<00:04, 63.86it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▊      | 181/469 [00:03<00:04, 59.66it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 196/469 [00:04<00:04, 61.62it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 204/469 [00:04<00:04, 62.72it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▋     | 218/469 [00:04<00:04, 59.41it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 232/469 [00:04<00:03, 62.17it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 247/469 [00:04<00:03, 61.83it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 255/469 [00:04<00:03, 66.16it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 269/469 [00:05<00:03, 63.44it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 285/469 [00:05<00:02, 68.19it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 299/469 [00:05<00:02, 64.76it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 314/469 [00:05<00:02, 65.81it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 70%|██████▉   | 328/469 [00:06<00:02, 62.39it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 342/469 [00:06<00:02, 57.65it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 356/469 [00:06<00:01, 59.12it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 363/469 [00:06<00:01, 61.50it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 377/469 [00:06<00:01, 62.91it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 391/469 [00:07<00:01, 61.11it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 406/469 [00:07<00:00, 65.16it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 90%|████████▉ | 420/469 [00:07<00:00, 60.68it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 434/469 [00:07<00:00, 62.77it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 442/469 [00:07<00:00, 66.00it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 456/469 [00:08<00:00, 61.97it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 469/469 [00:08<00:00, 55.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([128, 1, 28, 28])\ntorch.Size([96, 1, 28, 28])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m         latent \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(num_samples_per_class \u001b[38;5;241m*\u001b[39m num_class, params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim_latent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     75\u001b[0m         imgs_fake \u001b[38;5;241m=\u001b[39m generator(latent)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 76\u001b[0m         \u001b[43msave_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs_fake\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(generator\u001b[38;5;241m.\u001b[39mstate_dict(), ckpt_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(discriminator\u001b[38;5;241m.\u001b[39mstate_dict(), ckpt_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscriminator.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[18], line 76\u001b[0m, in \u001b[0;36msave_images\u001b[0;34m(imgs, idx, dirname)\u001b[0m\n\u001b[1;32m     74\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_yticklabels([])\n\u001b[1;32m     75\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_aspect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dirname)):\n\u001b[1;32m     79\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dirname))\n","\u001b[0;31mValueError\u001b[0m: axes don't match array"],"ename":"ValueError","evalue":"axes don't match array","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x1000 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAF0AAABdCAYAAADHcWrDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAA40lEQVR4nO3QQREAIAzAMMC/5+GCPGgU9LpnZlaeOjrgR00Hmg40HWg60HSg6UDTgaYDTQeaDjQdaDrQdKDpQNOBpgNNB5oONB1oOtB0oOlA04GmA00Hmg40HWg60HSg6UDTgaYDTQeaDjQdaDrQdKDpQNOBpgNNB5oONB1oOtB0oOlA04GmA00Hmg40HWg60HSg6UDTgaYDTQeaDjQdaDrQdKDpQNOBpgNNB5oONB1oOtB0oOlA04GmA00Hmg40HWg60HSg6UDTgaYDTQeaDjQdaDrQdKDpQNOBpgNNB5oONB24v+cEtncH7AQAAAAASUVORK5CYII="},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:38:30.572242Z","iopub.status.idle":"2024-11-06T10:38:30.572628Z","shell.execute_reply.started":"2024-11-06T10:38:30.572437Z","shell.execute_reply":"2024-11-06T10:38:30.572456Z"}},"outputs":[],"execution_count":null}]}