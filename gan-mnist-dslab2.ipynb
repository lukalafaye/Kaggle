{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9644358,"sourceType":"datasetVersion","datasetId":5887736},{"sourceId":145569,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":123427,"modelId":139891}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lukalafaye/gan-mnist-dslab2?scriptVersionId=206807218\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Recall / Precision stuff","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python3\nimport os\nfrom functools import partial\nfrom collections import namedtuple\nfrom glob import glob\nimport numpy as np\nfrom PIL import Image\nfrom argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\nfrom tqdm import tqdm\nfrom tqdm import trange\n\nimport torch\nimport torchvision.models as models\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, datasets\nfrom torchvision.utils import save_image\n\nManifold = namedtuple(\"Manifold\", [\"features\", \"radii\"])\nPrecisionAndRecall = namedtuple(\"PrecisionAndRecall\", [\"precision\", \"recall\"])\n\n\ndef convert_mnist_to_images(output_dir, num_images=100):\n    os.makedirs(output_dir, exist_ok=True)\n    transform = transforms.Compose([transforms.ToTensor()])\n    mnist_data = datasets.MNIST(\n        root=\"data/MNIST\", train=True, transform=transform, download=True\n    )\n\n    for i in range(num_images):\n        img, label = mnist_data[i]\n        save_image(img, os.path.join(output_dir, f\"real_{i}.png\"))\n    print(f\"Converted {num_images} MNIST images to PNG format in '{output_dir}'.\")\n\n\nclass IPR:\n    def __init__(self, batch_size=50, k=3, num_samples=10000, model=None):\n        self.manifold_ref = None\n        self.batch_size = batch_size\n        self.k = k\n        self.num_samples = num_samples\n        if model is None:\n            print(\n                \"loading vgg16 for improved precision and recall...\", end=\"\", flush=True\n            )\n            self.vgg16 = models.vgg16(pretrained=True).cuda().eval()\n            print(\"done\")\n        else:\n            self.vgg16 = model\n\n    def __call__(self, subject):\n        return self.precision_and_recall(subject)\n\n    def precision_and_recall(self, subject):\n        \"\"\"\n        Compute precision and recall for given subject\n        reference should be precomputed by IPR.compute_manifold_ref()\n        args:\n            subject: path or images\n                path: a directory containing images or precalculated .npz file\n                images: torch.Tensor of N x C x H x W\n        returns:\n            PrecisionAndRecall\n        \"\"\"\n        assert self.manifold_ref is not None, \"call IPR.compute_manifold_ref() first\"\n\n        manifold_subject = self.compute_manifold(subject)\n        precision = compute_metric(\n            self.manifold_ref, manifold_subject.features, \"computing precision...\"\n        )\n        recall = compute_metric(\n            manifold_subject, self.manifold_ref.features, \"computing recall...\"\n        )\n        return PrecisionAndRecall(precision, recall)\n\n    def compute_manifold_ref(self, path):\n        self.manifold_ref = self.compute_manifold(path)\n\n    def realism(self, image):\n        \"\"\"\n        args:\n            image: torch.Tensor of 1 x C x H x W\n        \"\"\"\n        feat = self.extract_features(image)\n        return realism(self.manifold_ref, feat)\n\n    def compute_manifold(self, input):\n        \"\"\"\n        Compute manifold of given input\n        args:\n            input: path or images, same as above\n        returns:\n            Manifold(features, radii)\n        \"\"\"\n        # features\n        if isinstance(input, str):\n            if input.endswith(\".npz\"):  # input is precalculated file\n                print(\"loading\", input)\n                f = np.load(input)\n                feats = f[\"feature\"]\n                radii = f[\"radii\"]\n                f.close()\n                return Manifold(feats, radii)\n            else:  # input is dir\n                feats = self.extract_features_from_files(input)\n        elif isinstance(input, torch.Tensor):\n            feats = self.extract_features(input)\n        elif isinstance(input, np.ndarray):\n            input = torch.Tensor(input)\n            feats = self.extract_features(input)\n        elif isinstance(input, list):\n            if isinstance(input[0], torch.Tensor):\n                input = torch.cat(input, dim=0)\n                feats = self.extract_features(input)\n            elif isinstance(input[0], np.ndarray):\n                input = np.concatenate(input, axis=0)\n                input = torch.Tensor(input)\n                feats = self.extract_features(input)\n            elif isinstance(input[0], str):  # input is list of fnames\n                feats = self.extract_features_from_files(input)\n            else:\n                raise TypeError\n        else:\n            print(type(input))\n            raise TypeError\n\n        # radii\n        distances = compute_pairwise_distances(feats)\n        radii = distances2radii(distances, k=self.k)\n        return Manifold(feats, radii)\n\n    def extract_features(self, images):\n        \"\"\"\n        Extract features of vgg16-fc2 for all images\n        params:\n            images: torch.Tensors of size N x C x H x W\n        returns:\n            A numpy array of dimension (num images, dims)\n        \"\"\"\n        desc = \"extracting features of %d images\" % images.size(0)\n        num_batches = int(np.ceil(images.size(0) / self.batch_size))\n        _, _, height, width = images.shape\n        if height != 224 or width != 224:\n            print(\"IPR: resizing %s to (224, 224)\" % str((height, width)))\n            resize = partial(F.interpolate, size=(224, 224))\n        else:\n\n            def resize(x):\n                return x\n\n        features = []\n        for bi in trange(num_batches, desc=desc):\n            start = bi * self.batch_size\n            end = start + self.batch_size\n            batch = images[start:end]\n            batch = resize(batch)\n            before_fc = self.vgg16.features(batch.cuda())\n            before_fc = before_fc.view(-1, 7 * 7 * 512)\n            feature = self.vgg16.classifier[:4](before_fc)\n            features.append(feature.cpu().data.numpy())\n\n        return np.concatenate(features, axis=0)\n\n    def extract_features_from_files(self, path_or_fnames):\n        \"\"\"\n        Extract features of vgg16-fc2 for all images in path\n        params:\n            path_or_fnames: dir containing images or list of fnames(str)\n        returns:\n            A numpy array of dimension (num images, dims)\n        \"\"\"\n\n        dataloader = get_custom_loader(\n            path_or_fnames, batch_size=self.batch_size, num_samples=self.num_samples\n        )\n        num_found_images = len(dataloader.dataset)\n        desc = \"extracting features of %d images\" % num_found_images\n        if num_found_images < self.num_samples:\n            print(\n                \"WARNING: num_found_images(%d) < num_samples(%d)\"\n                % (num_found_images, self.num_samples)\n            )\n\n        features = []\n        for batch in tqdm(dataloader, desc=desc):\n            before_fc = self.vgg16.features(batch.cuda())\n            before_fc = before_fc.view(-1, 7 * 7 * 512)\n            feature = self.vgg16.classifier[:4](before_fc)\n            features.append(feature.cpu().data.numpy())\n\n        return np.concatenate(features, axis=0)\n\n    def save_ref(self, fname):\n        print(\"saving manifold to\", fname, \"...\")\n        np.savez_compressed(\n            fname, feature=self.manifold_ref.features, radii=self.manifold_ref.radii\n        )\n\n\ndef compute_pairwise_distances(X, Y=None):\n    \"\"\"\n    args:\n        X: np.array of shape N x dim\n        Y: np.array of shape N x dim\n    returns:\n        N x N symmetric np.array\n    \"\"\"\n    num_X = X.shape[0]\n    if Y is None:\n        num_Y = num_X\n    else:\n        num_Y = Y.shape[0]\n    X = X.astype(np.float64)  # to prevent underflow\n    X_norm_square = np.sum(X**2, axis=1, keepdims=True)\n    if Y is None:\n        Y_norm_square = X_norm_square\n    else:\n        Y_norm_square = np.sum(Y**2, axis=1, keepdims=True)\n    X_square = np.repeat(X_norm_square, num_Y, axis=1)\n    Y_square = np.repeat(Y_norm_square.T, num_X, axis=0)\n    if Y is None:\n        Y = X\n    XY = np.dot(X, Y.T)\n    diff_square = X_square - 2 * XY + Y_square\n\n    # check negative distance\n    min_diff_square = diff_square.min()\n    if min_diff_square < 0:\n        idx = diff_square < 0\n        diff_square[idx] = 0\n        print(\n            \"WARNING: %d negative diff_squares found and set to zero, min_diff_square=\"\n            % idx.sum(),\n            min_diff_square,\n        )\n\n    distances = np.sqrt(diff_square)\n    return distances\n\n\ndef distances2radii(distances, k=3):\n    num_features = distances.shape[0]\n    radii = np.zeros(num_features)\n    for i in range(num_features):\n        radii[i] = get_kth_value(distances[i], k=k)\n    return radii\n\n\ndef get_kth_value(np_array, k):\n    kprime = k + 1  # kth NN should be (k+1)th because closest one is itself\n    idx = np.argpartition(np_array, kprime)\n    k_smallests = np_array[idx[:kprime]]\n    kth_value = k_smallests.max()\n    return kth_value\n\n\ndef compute_metric(manifold_ref, feats_subject, desc=\"\"):\n    num_subjects = feats_subject.shape[0]\n    count = 0\n    dist = compute_pairwise_distances(manifold_ref.features, feats_subject)\n    for i in trange(num_subjects, desc=desc):\n        count += (dist[:, i] < manifold_ref.radii).any()\n    return count / num_subjects\n\n\ndef is_in_ball(center, radius, subject):\n    return distance(center, subject) < radius\n\n\ndef distance(feat1, feat2):\n    return np.linalg.norm(feat1 - feat2)\n\n\ndef realism(manifold_real, feat_subject):\n    feats_real = manifold_real.features\n    radii_real = manifold_real.radii\n    diff = feats_real - feat_subject\n    dists = np.linalg.norm(diff, axis=1)\n    eps = 1e-6\n    ratios = radii_real / (dists + eps)\n    max_realism = float(ratios.max())\n    return max_realism\n\n\nclass ImageFolder(Dataset):\n    def __init__(self, root, transform=None):\n        # self.fnames = list(map(lambda x: os.path.join(root, x), os.listdir(root)))\n        self.fnames = glob(os.path.join(root, \"**\", \"*.jpg\"), recursive=True) + glob(\n            os.path.join(root, \"**\", \"*.png\"), recursive=True\n        )\n\n        self.transform = transform\n\n    def __getitem__(self, index):\n        image_path = self.fnames[index]\n        image = Image.open(image_path).convert(\"RGB\")\n        if self.transform is not None:\n            image = self.transform(image)\n        return image\n\n    def __len__(self):\n        return len(self.fnames)\n\n\nclass FileNames(Dataset):\n    def __init__(self, fnames, transform=None):\n        self.fnames = fnames\n        self.transform = transform\n\n    def __getitem__(self, index):\n        image_path = self.fnames[index]\n        image = Image.open(image_path).convert(\"RGB\")\n        if self.transform is not None:\n            image = self.transform(image)\n        return image\n\n    def __len__(self):\n        return len(self.fnames)\n\n\ndef get_custom_loader(\n    image_dir_or_fnames, image_size=224, batch_size=50, num_workers=4, num_samples=-1\n):\n    transform = []\n    transform.append(transforms.Resize([image_size, image_size]))\n    transform.append(transforms.ToTensor())\n    transform.append(\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    )\n    transform = transforms.Compose(transform)\n\n    if isinstance(image_dir_or_fnames, list):\n        dataset = FileNames(image_dir_or_fnames, transform)\n    elif isinstance(image_dir_or_fnames, str):\n        dataset = ImageFolder(image_dir_or_fnames, transform=transform)\n    else:\n        raise TypeError\n\n    if num_samples > 0:\n        dataset.fnames = dataset.fnames[:num_samples]\n    data_loader = DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True,\n    )\n    return data_loader\n\n\ndef toy():\n    offset = 2\n    feats_real = np.random.rand(10).reshape(-1, 1)\n    feats_fake = np.random.rand(10).reshape(-1, 1) + offset\n    feats_real[0] = offset\n    feats_fake[0] = 1\n    print(\"real:\", feats_real)\n    print(\"fake:\", feats_fake)\n\n    print(\"computing pairwise distances...\")\n    distances_real = compute_pairwise_distances(feats_real)\n    print(\"distances to radii...\")\n    radii_real = distances2radii(distances_real)\n    manifold_real = Manifold(feats_real, radii_real)\n\n    print(\"computing pairwise distances...\")\n    distances_fake = compute_pairwise_distances(feats_fake)\n    print(\"distances to radii...\")\n    radii_fake = distances2radii(distances_fake)\n    manifold_fake = Manifold(feats_fake, radii_fake)\n\n    precision = compute_metric(manifold_real, feats_fake)\n    recall = compute_metric(manifold_fake, feats_real)\n    print(\"precision:\", precision)\n    print(\"recall:\", recall)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:53.448075Z","iopub.execute_input":"2024-11-12T14:19:53.448515Z","iopub.status.idle":"2024-11-12T14:19:53.506643Z","shell.execute_reply.started":"2024-11-12T14:19:53.448459Z","shell.execute_reply":"2024-11-12T14:19:53.50575Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":"# SAN","metadata":{}},{"cell_type":"code","source":"!pip3 install torch torchview tqdm matplotlib pytorch-fid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:12.409989Z","iopub.execute_input":"2024-11-12T14:19:12.410337Z","iopub.status.idle":"2024-11-12T14:19:23.995886Z","shell.execute_reply.started":"2024-11-12T14:19:12.410302Z","shell.execute_reply":"2024-11-12T14:19:23.994795Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torchview in /opt/conda/lib/python3.10/site-packages (0.2.6)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: pytorch-fid in /opt/conda/lib/python3.10/site-packages (0.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pytorch-fid) (1.14.1)\nRequirement already satisfied: torchvision>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-fid) (0.19.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"# Generator","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np \nfrom torch.nn.utils import spectral_norm\n\nclass Generator(nn.Module):\n    def __init__(self, g_output_dim=784, dim_latent=100):\n        super(Generator, self).__init__()\n        self.fc1 = nn.Linear(100, 256)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        return torch.tanh(self.fc4(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:23.997288Z","iopub.execute_input":"2024-11-12T14:19:23.997648Z","iopub.status.idle":"2024-11-12T14:19:24.006896Z","shell.execute_reply.started":"2024-11-12T14:19:23.997611Z","shell.execute_reply":"2024-11-12T14:19:24.005925Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"# Discriminator","metadata":{}},{"cell_type":"code","source":"class BaseDiscriminator(nn.Module):\n    def __init__(self, d_input_dim=784):\n        super(BaseDiscriminator, self).__init__()\n        self.h_function = nn.Sequential(\n            #nn.Linear(d_input_dim, 512),\n            spectral_norm(nn.Linear(d_input_dim, 1024)),\n            nn.LeakyReLU(0.2),\n            #nn.Linear(1024, 512),\n            #nn.LeakyReLU(0.2),\n            #nn.Linear(512, 256),\n            spectral_norm(nn.Linear(1024, 512)),\n            nn.LeakyReLU(0.2),\n            #nn.Linear(256, 1)\n            spectral_norm(nn.Linear(512, 256)),\n            nn.LeakyReLU(0.2),\n        )\n\n        self.fc_w = nn.Parameter(torch.randn(1, 256))\n\n    def forward(self, x, flg_train: bool):        \n        h_feature = self.h_function(x)\n        weights = self.fc_w\n        out = (h_feature * weights).sum(dim=1)\n        return out\n\nclass SanDiscriminator(BaseDiscriminator):\n    def __init__(self, d_input_dim=784):\n        super(SanDiscriminator, self).__init__(d_input_dim)\n\n    def forward(self, x, flg_train: bool):\n        h_feature = self.h_function(x)        \n        weights = self.fc_w\n        direction = F.normalize(weights, dim=1)  # Normalize the last layer\n        scale = torch.norm(weights, dim=1).unsqueeze(1)\n        h_feature = h_feature * scale  # Keep the scale\n        if flg_train:  # For discriminator training\n            out_fun = (h_feature * direction.detach()).sum(dim=1)\n            out_dir = (h_feature.detach() * direction).sum(dim=1)\n            out = dict(fun=out_fun, dir=out_dir)\n        else:  # For generator training or inference\n            out = (h_feature * direction).sum(dim=1)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:24.008119Z","iopub.execute_input":"2024-11-12T14:19:24.008416Z","iopub.status.idle":"2024-11-12T14:19:24.020429Z","shell.execute_reply.started":"2024-11-12T14:19:24.008371Z","shell.execute_reply":"2024-11-12T14:19:24.019612Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"import torch\nfrom torchview import draw_graph\n\n# Define input dimensions and model\nd_input_dim = 784\nsample_model = SanDiscriminator(d_input_dim=d_input_dim)\n\n# Create a dummy input tensor with the appropriate input dimensions\ndummy_input = torch.randn(1, d_input_dim)\n\n# Generate the computational graph\n# Set `flg_train` as `True` for training visualization or `False` for inference visualization\ngraph = draw_graph(sample_model, input_data=[dummy_input, True], expand_nested=True)\n\ngraph.visual_graph\ngraph.visual_graph.format = \"png\"\ngraph.visual_graph.render(\"SanDiscriminator_Architecture\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:24.022857Z","iopub.execute_input":"2024-11-12T14:19:24.023191Z","iopub.status.idle":"2024-11-12T14:19:24.134096Z","shell.execute_reply.started":"2024-11-12T14:19:24.023157Z","shell.execute_reply":"2024-11-12T14:19:24.133153Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"'SanDiscriminator_Architecture.png'"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"import argparse\nimport json\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport tqdm\n\nfrom torch.utils.data import DataLoader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:24.135157Z","iopub.execute_input":"2024-11-12T14:19:24.135448Z","iopub.status.idle":"2024-11-12T14:19:24.141435Z","shell.execute_reply.started":"2024-11-12T14:19:24.135415Z","shell.execute_reply":"2024-11-12T14:19:24.140533Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"import os\nimport json\n\n# Define folder paths\nmnist_folder = './data/MNIST'\nlogs_folder = './logs'\nparams_path = './hparams/params.json'\n\n# Create folders if they don't exist\nos.makedirs(mnist_folder, exist_ok=True)\nos.makedirs(logs_folder, exist_ok=True)\nos.makedirs(os.path.dirname(params_path), exist_ok=True)\n\n# Define the parameters for params.json\nparams = {\n    \"dim_latent\": 100,\n    \"batch_size\": 128,\n    \"learning_rate_d\": 0.0001,\n    \"learning_rate_g\": 0.0007,    \n    \"beta_1\": 0.5,\n    \"beta_2\": 0.999,\n    \"num_epochs\": 150\n}\n\n# Write parameters to params.json\nwith open(params_path, 'w') as f:\n    json.dump(params, f, indent=4)\n\nprint(f\"Created folders '{mnist_folder}' and '{logs_folder}', and saved parameters to '{params_path}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:24.142861Z","iopub.execute_input":"2024-11-12T14:19:24.143449Z","iopub.status.idle":"2024-11-12T14:19:24.153829Z","shell.execute_reply.started":"2024-11-12T14:19:24.143403Z","shell.execute_reply":"2024-11-12T14:19:24.152911Z"}},"outputs":[{"name":"stdout","text":"Created folders './data/MNIST' and './logs', and saved parameters to './hparams/params.json'.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"default_args = {\n    \"datadir\": \"./data/MNIST\",\n    \"params\": \"./hparams/params.json\",\n    \"model\": \"san\",\n    \"enable_class\": False,\n    \"logdir\": \"./logs\",\n    \"device\": 0\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:24.154977Z","iopub.execute_input":"2024-11-12T14:19:24.155279Z","iopub.status.idle":"2024-11-12T14:19:24.162055Z","shell.execute_reply.started":"2024-11-12T14:19:24.155238Z","shell.execute_reply":"2024-11-12T14:19:24.16125Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"from argparse import Namespace\nargs = Namespace(**default_args)\n\nprint(args.datadir)        # Access './data/MNIST'\nprint(args.params)         # Access './hparams/params.json'\nprint(args.model)          # Access 'gan'\nprint(args.enable_class)   # Access False\nprint(args.logdir)         # Access './logs'\nprint(args.device)         # Access 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:24.163312Z","iopub.execute_input":"2024-11-12T14:19:24.163974Z","iopub.status.idle":"2024-11-12T14:19:24.1723Z","shell.execute_reply.started":"2024-11-12T14:19:24.163929Z","shell.execute_reply":"2024-11-12T14:19:24.17142Z"}},"outputs":[{"name":"stdout","text":"./data/MNIST\n./hparams/params.json\nsan\nFalse\n./logs\n0\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# Train functions\n\ndef update_discriminator(x, discriminator, generator, optimizer, params):\n    bs = x.size(0)\n    device = x.device\n\n    optimizer.zero_grad()\n\n    # for data (ground-truth) distribution\n    disc_real = discriminator(x, flg_train=True)\n    loss_real = eval('compute_loss_'+args.model)(disc_real, loss_type='real')\n\n    # for generator distribution\n    latent = torch.randn(bs, params[\"dim_latent\"], device=device)\n    img_fake = generator(latent)\n    disc_fake = discriminator(img_fake.detach(), flg_train=True)\n    loss_fake = eval('compute_loss_'+args.model)(disc_fake, loss_type='fake')\n\n\n    loss_d = loss_real + loss_fake\n    loss_d.backward()\n    optimizer.step()\n    \n    return loss_real, loss_fake\n\ndef update_generator(discriminator, generator, optimizer, params, device):\n    optimizer.zero_grad()\n\n    bs = params['batch_size']\n    latent = torch.randn(bs, params[\"dim_latent\"], device=device)\n\n    batch_fake = generator(latent)\n\n    disc_gen = discriminator(batch_fake, flg_train=False)\n    loss_g = - disc_gen.mean()\n    loss_g.backward()\n    optimizer.step()\n\n    if torch.isnan(loss_g).any():\n        print(\"NaN detected in generator loss!\")\n        return loss_g\n    return loss_g\n    \n\ndef compute_loss_gan(disc, loss_type):\n    assert (loss_type in ['real', 'fake'])\n    if 'real' == loss_type:\n        loss = (1. - disc).relu().mean() # Hinge loss\n    else: # 'fake' == loss_type\n        loss = (1. + disc).relu().mean() # Hinge loss\n\n    return loss\n\n\ndef compute_loss_san(disc, loss_type):\n    assert (loss_type in ['real', 'fake'])\n    if 'real' == loss_type:\n        loss_fun = (1. - disc['fun']).relu().mean() # Hinge loss for function h\n        loss_dir = - disc['dir'].mean() # Wasserstein loss for omega\n    else: # 'fake' == loss_type\n        loss_fun = (1. + disc['fun']).relu().mean() # Hinge loss for function h\n        loss_dir = disc['dir'].mean() # Wasserstein loss for omega\n\n    lambd = 5\n    loss = loss_fun + lambd * loss_dir\n\n    return loss\n\n\ndef save_images(imgs, idx, dirname='test'):\n    # Ensure imgs is a numpy array if it's a tensor\n    if isinstance(imgs, torch.Tensor):\n        imgs = imgs.cpu().data.numpy()\n\n    # If the images are grayscale (1 channel), repeat them to make them RGB (3 channels)\n    if imgs.shape[1] == 1:  # This checks if there is only 1 channel (grayscale)\n        imgs = np.repeat(imgs, 3, axis=1)  # Repeat the grayscale channel 3 times to make RGB\n\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(f'out/{dirname}/'):\n        os.makedirs(f'out/{dirname}/')\n\n    # Set up the plot\n    fig = plt.figure(figsize=(10, 10))\n    gs = gridspec.GridSpec(10, 10)\n    gs.update(wspace=0.05, hspace=0.05)\n\n    # Loop through the batch of images\n    for i, sample in enumerate(imgs):\n        ax = plt.subplot(gs[i])\n        plt.axis('off')\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        ax.set_aspect('equal')\n\n        # Ensure each sample has the shape (height, width, channels) for imshow\n        sample = sample.transpose((1, 2, 0))  # Convert from (C, H, W) -> (H, W, C)\n\n        # Plot the image\n        plt.imshow(sample)\n\n    # Save the plot to the directory\n    plt.savefig(f'out/{dirname}/{str(idx).zfill(3)}.png', bbox_inches=\"tight\")\n    plt.close(fig)\n\ndef plot_generated_images(generator, epoch, num_images=20):\n    \"\"\"Function to plot and display generated images from the generator.\"\"\"\n    generator.eval()\n    with torch.no_grad():\n        noise = torch.randn(num_images, 100).to(device)\n        generated_images = generator(noise)\n        generated_images = generated_images.view(-1, 1, 28, 28).cpu()\n\n        # Create two rows of 10 images\n        fig, axes = plt.subplots(2, 10, figsize=(15, 6))\n        axes = axes.flatten()  # Flatten the axes array for easy iteration\n        for ax, img in zip(axes, generated_images):\n            ax.imshow(img.squeeze(), cmap='gray')\n            ax.axis('off')\n        plt.tight_layout()\n        plt.show()\n\ndef plot_losses(G_losses, D_real_losses, D_fake_losses):\n    G_losses = [loss.detach().cpu().numpy() for loss in G_losses]\n    D_real_losses = [loss.detach().cpu().numpy() for loss in D_real_losses]\n    D_fake_losses = [loss.detach().cpu().numpy() for loss in D_fake_losses]\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(G_losses, label=\"Generator Loss\")\n    plt.plot(D_real_losses, label=\"Discriminator Real Loss\")\n    plt.plot(D_fake_losses, label=\"Discriminator Fake Loss\")\n    \n    plt.title(\"Generator and Discriminator Losses Over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    \n    plt.ylim(-5, 5)\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:24.173855Z","iopub.execute_input":"2024-11-12T14:19:24.174301Z","iopub.status.idle":"2024-11-12T14:19:24.200478Z","shell.execute_reply.started":"2024-11-12T14:19:24.174253Z","shell.execute_reply":"2024-11-12T14:19:24.199386Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"device = f'cuda:{args.device}' if args.device is not None else 'cpu'\nmodel_name = args.model\nprint(model_name)\nif not model_name in ['gan', 'san']:\n    raise RuntimeError(\"A model name have to be 'gan' or 'san'.\")\n    \nexperiment_name = model_name + \"_cond\" if args.enable_class else model_name\n\ntransform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\n# dataloading\nnum_class = 10\ntrain_dataset = datasets.MNIST(root=args.datadir, transform=transform, train=True, download=True)\ntrain_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], num_workers=8,\n                          pin_memory=True, persistent_workers=True, shuffle=True)\n\ntest_dataset = datasets.MNIST(root=args.datadir, transform=transform, train=False, download=True)\ntest_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], num_workers=8,\n                         pin_memory=True, persistent_workers=True, shuffle=False)\n\n# model\ngenerator = Generator(g_output_dim=784)\n\nif 'gan' == args.model:\n    discriminator = BaseDiscriminator(d_input_dim=784)\nelse: # 'san' == args.model\n    discriminator = SanDiscriminator(d_input_dim=784)\ngenerator = generator.to(device)\ndiscriminator = discriminator.to(device)\n\n# optimizer\nbetas = (params[\"beta_1\"], params[\"beta_2\"])\noptimizer_G = optim.Adam(generator.parameters(), lr=params[\"learning_rate_g\"], betas=betas)\noptimizer_D = optim.Adam(discriminator.parameters(), lr=params[\"learning_rate_d\"], betas=betas)\n\nckpt_dir = f'{args.logdir}/{experiment_name}/'\nif not os.path.exists(args.logdir):\n    os.mkdir(args.logdir)\nif not os.path.exists(ckpt_dir):\n    os.mkdir(ckpt_dir)\n\nsteps_per_epoch = len(train_loader)\n\nmsg = [\"\\t{0}: {1}\".format(key, val) for key, val in params.items()]\nprint(\"hyperparameters: \\n\" + \"\\n\".join(msg))\n\n# eval initial states\nnum_samples_per_class = 10\nwith torch.no_grad():\n    latent = torch.randn(num_samples_per_class * num_class, params[\"dim_latent\"]).cuda()\n    imgs_fake = generator(latent)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:24.201839Z","iopub.execute_input":"2024-11-12T14:19:24.202206Z","iopub.status.idle":"2024-11-12T14:19:24.33879Z","shell.execute_reply.started":"2024-11-12T14:19:24.202161Z","shell.execute_reply":"2024-11-12T14:19:24.337549Z"}},"outputs":[{"name":"stdout","text":"san\nhyperparameters: \n\tdim_latent: 100\n\tbatch_size: 128\n\tlearning_rate_d: 0.0001\n\tlearning_rate_g: 0.0007\n\tbeta_1: 0.5\n\tbeta_2: 0.999\n\tnum_epochs: 150\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## Save test images from test data loader\n","metadata":{}},{"cell_type":"code","source":"# Directory to save images\nmnist_image_dir = 'MNIST_images'\nos.makedirs(mnist_image_dir, exist_ok=True)\n\n# Define the inverse transform to unnormalize the images\ninv_transform = transforms.Compose([\n    transforms.Normalize(mean=[-1.0], std=[2.0])  # Undo the normalization (0.5 mean, 0.5 std)\n])\n\n# Save each image\nfor i, (image, _) in enumerate(test_dataset):\n    # Inverse normalize and convert to PIL format\n    image = inv_transform(image)\n    image = transforms.ToPILImage()(image)\n    \n    # Save as PNG\n    image.save(os.path.join(mnist_image_dir, f\"image_{i}.png\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:24.340204Z","iopub.execute_input":"2024-11-12T14:19:24.340621Z","iopub.status.idle":"2024-11-12T14:19:31.696395Z","shell.execute_reply.started":"2024-11-12T14:19:24.340568Z","shell.execute_reply":"2024-11-12T14:19:31.695564Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"!ls -1 MNIST_images | wc -l","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:31.697905Z","iopub.execute_input":"2024-11-12T14:19:31.698287Z","iopub.status.idle":"2024-11-12T14:19:32.734184Z","shell.execute_reply.started":"2024-11-12T14:19:31.698251Z","shell.execute_reply":"2024-11-12T14:19:32.73293Z"}},"outputs":[{"name":"stdout","text":"10000\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"## Functions to evaluate PR and FID","metadata":{}},{"cell_type":"code","source":"import torchvision\nimport shutil\n\ndef generate_samples(generator):\n    directory = '/kaggle/working/samples'\n    # Remove the directory and its contents\n    shutil.rmtree(directory, ignore_errors=True)\n    \n    model = torch.nn.DataParallel(generator).cuda()\n    model.eval()\n    \n    print('Model loaded.')\n    \n    \n    print('Start Generating')\n    os.makedirs('samples', exist_ok=True)\n    \n    image_paths = []\n    batch_size = params[\"batch_size\"]\n    dim_latent = params[\"dim_latent\"]\n    \n    n_samples = 0\n    with torch.no_grad():\n        while n_samples<10000:\n            z = torch.randn(batch_size, dim_latent).cuda()\n            x = model(z)\n            x = x.reshape(batch_size, 28, 28)\n            for k in range(x.shape[0]):\n                if n_samples<10000:\n                    image_path = os.path.join('samples', f'{n_samples}.png')\n                    torchvision.utils.save_image(x[k:k+1], image_path)         \n                    image_paths.append(image_path)  # Store image path\n                    n_samples += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:32.738341Z","iopub.execute_input":"2024-11-12T14:19:32.738828Z","iopub.status.idle":"2024-11-12T14:19:32.74811Z","shell.execute_reply.started":"2024-11-12T14:19:32.738792Z","shell.execute_reply":"2024-11-12T14:19:32.747202Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"import subprocess\nfrom pathlib import Path\n\ndef eval_model(generator):\n    # Generate the samples\n    generate_samples(generator)\n    real_images_dir = Path('/kaggle/working/MNIST_images')\n    fake_images_dir = Path('/kaggle/working/samples')\n\n    # Calculate precision and recall\n    ipr = IPR(batch_size=50, k=3, num_samples=10000)\n    ipr.compute_manifold_ref(str(real_images_dir))\n    precision, recall = ipr.precision_and_recall(str(fake_images_dir))\n\n    print(\"Precision:\", precision)\n    print(\"Recall:\", recall)\n\n    # Run FID score calculation\n    command = [\"python\", \"-m\", \"pytorch_fid\", \"samples\", \"MNIST_images\", \"--device\", \"cuda:0\"]\n    result = subprocess.run(command, check=True, capture_output=True, text=True)\n    \n    # Parse the output to extract the FID score\n    output = result.stdout\n    fid_score = None\n    for line in output.splitlines():\n        if \"FID:\" in line:\n            fid_score = float(line.split(\":\")[-1].strip())\n            break\n\n    print(\"FID:\", fid_score)\n    \n    return precision, recall, fid_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:32.749551Z","iopub.execute_input":"2024-11-12T14:19:32.749872Z","iopub.status.idle":"2024-11-12T14:19:32.763444Z","shell.execute_reply.started":"2024-11-12T14:19:32.749838Z","shell.execute_reply":"2024-11-12T14:19:32.762543Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_precision_recall_fid(precision_scores, recall_scores, fid_scores):\n    epochs = range(1, len(precision_scores) + 1)\n    \n    plt.figure(figsize=(15, 5))\n    \n    # Plot Precision\n    plt.subplot(1, 3, 1)\n    plt.plot(epochs, precision_scores, label=\"Precision\", marker='o')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Precision\")\n    plt.title(\"Precision over Epochs\")\n    plt.grid(True)\n    \n    # Plot Recall\n    plt.subplot(1, 3, 2)\n    plt.plot(epochs, recall_scores, label=\"Recall\", marker='o')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Recall\")\n    plt.title(\"Recall over Epochs\")\n    plt.grid(True)\n    \n    # Plot FID Score\n    plt.subplot(1, 3, 3)\n    plt.plot(epochs, fid_scores, label=\"FID\", marker='o')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"FID Score\")\n    plt.title(\"FID Score over Epochs\")\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:32.764655Z","iopub.execute_input":"2024-11-12T14:19:32.764987Z","iopub.status.idle":"2024-11-12T14:19:32.777685Z","shell.execute_reply.started":"2024-11-12T14:19:32.764954Z","shell.execute_reply":"2024-11-12T14:19:32.776782Z"}},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:19:32.778641Z","iopub.execute_input":"2024-11-12T14:19:32.778927Z","iopub.status.idle":"2024-11-12T14:19:32.788441Z","shell.execute_reply.started":"2024-11-12T14:19:32.778895Z","shell.execute_reply":"2024-11-12T14:19:32.787654Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"G_losses = []\nD_real_losses = []\nD_fake_losses = [] \nprecision_scores = []\nrecall_scores = []\nfid_scores = []\n\n# main training loop\nfor n in range(params[\"num_epochs\"]):\n    loader = iter(train_loader)\n\n    print(\"epoch: {0}/{1}\".format(n + 1, params[\"num_epochs\"]))\n    G_loss_epoch = 0\n    D_real_loss_epoch = 0\n    D_fake_loss_epoch = 0\n\n    for i in trange(steps_per_epoch):\n        x, class_ids = next(loader)\n        x = x.to(device)\n        x = x.view(x.size(0), -1)\n\n        loss_real, loss_fake = update_discriminator(x, discriminator, generator, optimizer_D, params)\n        G_loss = update_generator(discriminator, generator, optimizer_G, params, device)\n\n        D_real_loss_epoch += loss_real\n        D_fake_loss_epoch += loss_fake\n        G_loss_epoch += G_loss\n\n    if (n >= 20) and (n % 20) == 0:\n        precision, recall, fid_score = eval_model(generator)\n        precision_scores.append(precision)\n        recall_scores.append(recall)\n        fid_scores.append(fid_score)\n        plot_precision_recall_fid(precision_scores, recall_scores, fid_scores)\n\n    # Store the average loss per epoch\n    print(\"D-real:\", D_real_loss_epoch / len(train_loader))\n    print(\"D-fake:\", D_fake_loss_epoch / len(train_loader))\n    print(\"G-fake:\", G_loss_epoch / len(train_loader))\n    \n    D_real_losses.append(D_real_loss_epoch / len(train_loader))\n    D_fake_losses.append(D_fake_loss_epoch / len(train_loader))\n    \n    G_losses.append(G_loss_epoch / len(train_loader))\n    \n\n    plot_generated_images(generator, n+1)\n    \n    torch.save(generator.state_dict(), ckpt_dir + \"g.\" + str(n) + \".tmp\")\n    torch.save(discriminator.state_dict(), ckpt_dir + \"d.\" + str(n) + \".tmp\")\n\n\n    # eval\n    with torch.no_grad():\n        latent = torch.randn(num_samples_per_class * num_class, params[\"dim_latent\"]).cuda()\n        imgs_fake = generator(latent).cpu().data.numpy()\n        imgs_fake = imgs_fake.reshape(-1, 1, 28, 28)\n        save_images(imgs_fake, n, dirname=experiment_name)\n\n    plot_losses(G_losses, D_real_losses, D_fake_losses)\n\ntorch.save(generator.state_dict(), ckpt_dir + \"generator.pt\")\ntorch.save(discriminator.state_dict(), ckpt_dir + \"discriminator.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T14:20:08.869Z","iopub.execute_input":"2024-11-12T14:20:08.869423Z","iopub.status.idle":"2024-11-12T14:21:39.938553Z","shell.execute_reply.started":"2024-11-12T14:20:08.86938Z","shell.execute_reply":"2024-11-12T14:21:39.937061Z"}},"outputs":[{"name":"stdout","text":"epoch: 1/150\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/469 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Model loaded.\nStart Generating\nloading vgg16 for improved precision and recall...","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"done\n","output_type":"stream"},{"name":"stderr","text":"\nextracting features of 100 images:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\nextracting features of 100 images:  50%|█████     | 1/2 [00:00<00:00,  1.77it/s]\u001b[A\nextracting features of 100 images: 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\u001b[A\n\nextracting features of 100 images:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\nextracting features of 100 images:  50%|█████     | 1/2 [00:00<00:00,  2.48it/s]\u001b[A\nextracting features of 100 images: 100%|██████████| 2/2 [00:00<00:00,  3.42it/s]\u001b[A\n\ncomputing precision...: 100%|██████████| 100/100 [00:00<00:00, 59468.37it/s]\n\ncomputing recall...: 100%|██████████| 100/100 [00:00<00:00, 16796.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Precision: 0.0\nRecall: 0.0\nFID: 324.6210298843906\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 3 Axes>","image/png":"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"},"metadata":{}},{"name":"stderr","text":"  4%|▍         | 20/469 [01:11<10:09,  1.36s/it] ","output_type":"stream"},{"name":"stdout","text":"Model loaded.\nStart Generating\nloading vgg16 for improved precision and recall...","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"done\n","output_type":"stream"},{"name":"stderr","text":"\nextracting features of 100 images:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\nextracting features of 100 images:  50%|█████     | 1/2 [00:00<00:00,  2.64it/s]\u001b[A\nextracting features of 100 images: 100%|██████████| 2/2 [00:00<00:00,  3.56it/s]\u001b[A\n\nextracting features of 100 images:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\nextracting features of 100 images:  50%|█████     | 1/2 [00:00<00:00,  2.59it/s]\u001b[A\nextracting features of 100 images: 100%|██████████| 2/2 [00:00<00:00,  3.54it/s]\u001b[A\n\ncomputing precision...: 100%|██████████| 100/100 [00:00<00:00, 67378.38it/s]\n\ncomputing recall...: 100%|██████████| 100/100 [00:00<00:00, 69672.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Precision: 0.0\nRecall: 0.0\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 20/469 [01:30<33:50,  4.52s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[59], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m G_loss_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m G_loss\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     precision, recall, fid_score \u001b[38;5;241m=\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     precision_scores\u001b[38;5;241m.\u001b[39mappend(precision)\n\u001b[1;32m     32\u001b[0m     recall_scores\u001b[38;5;241m.\u001b[39mappend(recall)\n","Cell \u001b[0;32mIn[51], line 20\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Run FID score calculation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m command \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-m\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch_fid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMNIST_images\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--device\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Parse the output to extract the FID score\u001b[39;00m\n\u001b[1;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstdout\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:2021\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2015\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2016\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2019\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2021\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":59}]}