{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9644358,"sourceType":"datasetVersion","datasetId":5887736},{"sourceId":145569,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":123427,"modelId":139891}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lukalafaye/gan-mnist-dslab2?scriptVersionId=205598551\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nos.environ['PYTHON_PATH'] = \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2024-11-06T11:09:45.469444Z","iopub.execute_input":"2024-11-06T11:09:45.469924Z","iopub.status.idle":"2024-11-06T11:09:45.475808Z","shell.execute_reply.started":"2024-11-06T11:09:45.469872Z","shell.execute_reply":"2024-11-06T11:09:45.474625Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Generator(nn.Module):\n    def __init__(self, g_output_dim):\n        super(Generator, self).__init__()       \n        self.fc1 = nn.Linear(100, 256)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features * 2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features * 2)\n        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n\n    def forward(self, x): \n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        return torch.tanh(self.fc4(x))\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, d_input_dim):\n        super(SanDiscriminator, self).__init__()\n        self.fc1 = nn.Linear(d_input_dim, 1024)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features // 2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features // 2)\n        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n        \n        # Self-attention inspired parameters\n        self.attention_weights = nn.Parameter(torch.randn(1, self.fc3.out_features))\n\n    def forward(self, x):\n        # Extract features through fully connected layers\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        x = torch.sigmoid(self.fc4(x))\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args = argparse.Namespace(batch_size=20)  # Set default value\n\nprint('Model Loading...')\n# Model Pipeline\nmnist_dim = 784\n\nmodel = Generator(g_output_dim = mnist_dim).cuda()\nmodel = load_model(model, '/kaggle/input/g/pytorch/v2/1/')\nmodel = torch.nn.DataParallel(model).cuda()\nmodel.eval()\n\nprint('Model loaded.')\n\n\nprint('Start Generating')\nos.makedirs('samples', exist_ok=True)\n\nimage_paths = []\n\nn_samples = 0\nwith torch.no_grad():\n    while n_samples<10000:\n        z = torch.randn(args.batch_size, 100).cuda()\n        x = model(z)\n        x = x.reshape(args.batch_size, 28, 28)\n        for k in range(x.shape[0]):\n            if n_samples<10000:\n                image_path = os.path.join('samples', f'{n_samples}.png')\n                torchvision.utils.save_image(x[k:k+1], image_path)         \n                image_paths.append(image_path)  # Store image path\n                n_samples += 1","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:09.451836Z","iopub.execute_input":"2024-11-01T15:00:09.452635Z","iopub.status.idle":"2024-11-01T15:00:16.476086Z","shell.execute_reply.started":"2024-11-01T15:00:09.452596Z","shell.execute_reply":"2024-11-01T15:00:16.475119Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import display, Image\n\nfor img_path in image_paths[:50]:  # Slice to get only the first 10 images\n    display(Image(filename=img_path))","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:18.957416Z","iopub.execute_input":"2024-11-01T15:00:18.958387Z","iopub.status.idle":"2024-11-01T15:00:19.056568Z","shell.execute_reply.started":"2024-11-01T15:00:18.958332Z","shell.execute_reply":"2024-11-01T15:00:19.055706Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:22.633304Z","iopub.execute_input":"2024-11-01T15:00:22.633909Z","iopub.status.idle":"2024-11-01T15:00:22.63818Z","shell.execute_reply.started":"2024-11-01T15:00:22.633869Z","shell.execute_reply":"2024-11-01T15:00:22.637156Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\nfrom tqdm import trange\nimport argparse\nfrom torchvision import datasets, transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom model import Generator, Discriminator\nfrom utils import D_train, G_train, save_models\nfrom IPython.display import display \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nparser = argparse.ArgumentParser(description='Train Normalizing Flow.')\nparser.add_argument(\"--epochs\", type=int, default=400, help=\"Number of epochs for training.\")\nparser.add_argument(\"--lr\", type=float, default=0.0001, help=\"The learning rate to use for training.\")\nparser.add_argument(\"--batch_size\", type=int, default=1024, help=\"Size of mini-batches for SGD\")\nargs = parser.parse_args(args=[])\n\nos.makedirs('checkpoints', exist_ok=True)\nos.makedirs('data', exist_ok=True)\n\nprint('Dataset loading...')\ntransform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\ntrain_dataset = datasets.MNIST(root='data/MNIST/', train=True, transform=transform, download=True)\ntest_dataset = datasets.MNIST(root='data/MNIST/', train=False, transform=transform, download=False)\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                           batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n                                          batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True)\nprint('Dataset Loaded.')\n\nprint('Model Loading...')\nmnist_dim = 784\nG = torch.nn.DataParallel(Generator(g_output_dim=mnist_dim)).to(device)\nD = torch.nn.DataParallel(Discriminator(mnist_dim)).to(device)\nprint('Model loaded.')\n\ncriterion = nn.BCELoss().to(device)\nG_optimizer = optim.Adam(G.parameters(), lr=args.lr)\nD_optimizer = optim.Adam(D.parameters(), lr=args.lr)\n\nprint('Start Training:')\n\ndef plot_generated_images(generator, epoch, num_images=20):\n    \"\"\"Function to plot and display generated images from the generator.\"\"\"\n    generator.eval()\n    with torch.no_grad():\n        noise = torch.randn(num_images, 100).to(device)\n        generated_images = generator(noise)\n        generated_images = generated_images.view(-1, 1, 28, 28).cpu()\n\n        # Create two rows of 10 images\n        fig, axes = plt.subplots(2, 10, figsize=(15, 6))\n        axes = axes.flatten()  # Flatten the axes array for easy iteration\n        for ax, img in zip(axes, generated_images):\n            ax.imshow(img.squeeze(), cmap='gray')\n            ax.axis('off')\n        plt.tight_layout()\n        plt.show()\n\ndef plot_losses(G_losses, D_losses):\n    \"\"\"Function to plot the losses over epochs.\"\"\"\n    plt.figure(figsize=(10, 5))\n    plt.plot(G_losses, label=\"Generator Loss\")\n    plt.plot(D_losses, label=\"Discriminator Loss\")\n    plt.title(\"Generator and Discriminator Losses Over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\n\n# Initialize lists to store the losses\nG_losses = []\nD_losses = []\n\nn_epoch = args.epochs\nfor epoch in trange(1, n_epoch + 1, leave=True):\n    print(epoch)\n    G_loss_epoch = 0\n    D_loss_epoch = 0\n    \n    for batch_idx, (x, _) in enumerate(train_loader):\n        x = x.view(-1, mnist_dim).to(device)\n        \n        D_loss, _, _ = D_train(x, G, D, D_optimizer, criterion)  # Capture only the first return value\n        G_loss, _ = G_train(x, G, D, G_optimizer, criterion)  # Capture only the first return value\n\n        # Accumulate the losses for the current epoch\n        D_loss_epoch += D_loss\n        G_loss_epoch += G_loss\n\n    # Store the average loss per epoch\n    D_losses.append(D_loss_epoch / len(train_loader))\n    G_losses.append(G_loss_epoch / len(train_loader))\n\n    print(f\"Epoch [{epoch}/{n_epoch}], D Loss: {D_losses[-1]:.4f}, G Loss: {G_losses[-1]:.4f}\")\n\n    # Save models and generate images every 10 epochs\n    if epoch % 10 == 0:\n        save_models(G, D, 'checkpoints')\n        plot_generated_images(G, epoch)\n\n# After training, plot the losses\nplot_losses(G_losses, D_losses)\n\nprint('Training done')","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:29.956356Z","iopub.execute_input":"2024-11-01T15:00:29.9571Z","iopub.status.idle":"2024-11-01T15:39:02.826613Z","shell.execute_reply.started":"2024-11-01T15:00:29.957039Z","shell.execute_reply":"2024-11-01T15:39:02.825489Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls checkpoints","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:54:31.632527Z","iopub.execute_input":"2024-11-01T15:54:31.633368Z","iopub.status.idle":"2024-11-01T15:54:32.641225Z","shell.execute_reply.started":"2024-11-01T15:54:31.633312Z","shell.execute_reply":"2024-11-01T15:54:32.640045Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_models(generator, discriminator, epoch, g_losses, d_losses, path='checkpoints'):\n    checkpoint = {\n        'epoch': epoch,\n        'G_state_dict': generator.state_dict(),\n        'D_state_dict': discriminator.state_dict(),\n        'G_optimizer_state_dict': G_optimizer.state_dict(),\n        'D_optimizer_state_dict': D_optimizer.state_dict(),\n        'G_losses': g_losses,\n        'D_losses': d_losses\n    }\n    torch.save(checkpoint, os.path.join(path, 'model_checkpoint.pth'))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:54:33.398018Z","iopub.execute_input":"2024-11-01T15:54:33.398465Z","iopub.status.idle":"2024-11-01T15:54:33.405294Z","shell.execute_reply.started":"2024-11-01T15:54:33.398423Z","shell.execute_reply":"2024-11-01T15:54:33.40421Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_models(generator, discriminator, epoch, g_losses, d_losses)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:54:35.252957Z","iopub.execute_input":"2024-11-01T15:54:35.253359Z","iopub.status.idle":"2024-11-01T15:54:35.580072Z","shell.execute_reply.started":"2024-11-01T15:54:35.25332Z","shell.execute_reply":"2024-11-01T15:54:35.578907Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_checkpoint(generator, discriminator, g_optimizer, d_optimizer, path='checkpoints/model_checkpoint.pth'):\n    checkpoint = torch.load(path)\n    generator.load_state_dict(checkpoint['G_state_dict'])\n    discriminator.load_state_dict(checkpoint['D_state_dict'])\n    g_optimizer.load_state_dict(checkpoint['G_optimizer_state_dict'])\n    d_optimizer.load_state_dict(checkpoint['D_optimizer_state_dict'])\n    start_epoch = checkpoint['epoch'] + 1\n    g_losses = checkpoint['G_losses']\n    d_losses = checkpoint['D_losses']\n    return start_epoch, g_losses, d_losses\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.396905Z","iopub.status.idle":"2024-10-27T17:02:17.397277Z","shell.execute_reply.started":"2024-10-27T17:02:17.397077Z","shell.execute_reply":"2024-10-27T17:02:17.397114Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if a checkpoint exists to resume from\ncheckpoint_path = 'checkpoints/model_checkpoint.pth'\nif os.path.exists(checkpoint_path):\n    print(\"Loading checkpoint...\")\n    start_epoch, G_losses, D_losses = load_checkpoint(G, D, G_optimizer, D_optimizer, checkpoint_path)\n    print(f\"Resuming from epoch {start_epoch}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.398682Z","iopub.status.idle":"2024-10-27T17:02:17.399054Z","shell.execute_reply.started":"2024-10-27T17:02:17.398878Z","shell.execute_reply":"2024-10-27T17:02:17.398898Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_epoch=30\nfor epoch in trange(1, n_epoch + 1, leave=True):\n    print(epoch)\n    G_loss_epoch = 0\n    D_loss_epoch = 0\n    \n    for batch_idx, (x, _) in enumerate(train_loader):\n        x = x.view(-1, mnist_dim).to(device)\n        \n        D_loss, _, _ = D_train(x, G, D, D_optimizer, criterion)  # Capture only the first return value\n        G_loss, _ = G_train(x, G, D, G_optimizer, criterion)  # Capture only the first return value\n\n        # Accumulate the losses for the current epoch\n        D_loss_epoch += D_loss\n        G_loss_epoch += G_loss\n\n    # Store the average loss per epoch\n    D_losses.append(D_loss_epoch / len(train_loader))\n    G_losses.append(G_loss_epoch / len(train_loader))\n\n    print(f\"Epoch [{epoch}/{n_epoch}], D Loss: {D_losses[-1]:.4f}, G Loss: {G_losses[-1]:.4f}\")\n\n    # Save models and generate images every 10 epochs\n    if epoch % 10 == 0:\n        save_models(G, D, 'checkpoints')\n        plot_generated_images(G, epoch)\n\n# After training, plot the losses\nplot_losses(G_losses, D_losses)\n\nprint('Training done')","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.400518Z","iopub.status.idle":"2024-10-27T17:02:17.400886Z","shell.execute_reply.started":"2024-10-27T17:02:17.400699Z","shell.execute_reply":"2024-10-27T17:02:17.400724Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(G.state_dict(), 'generator2.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.402246Z","iopub.status.idle":"2024-10-27T17:02:17.402704Z","shell.execute_reply.started":"2024-10-27T17:02:17.402464Z","shell.execute_reply":"2024-10-27T17:02:17.402488Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SAN","metadata":{}},{"cell_type":"code","source":"!pip install torch torchvision tqdm matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T13:19:50.672646Z","iopub.execute_input":"2024-11-06T13:19:50.673301Z","iopub.status.idle":"2024-11-06T13:20:03.295613Z","shell.execute_reply.started":"2024-11-06T13:19:50.673257Z","shell.execute_reply":"2024-11-06T13:20:03.294489Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Generator","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np \n\nclass Generator(nn.Module):\n    def __init__(self, g_output_dim=784, dim_latent=100):\n        super(Generator, self).__init__()\n        self.fc1 = nn.Linear(100, 256)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        return torch.tanh(self.fc4(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T13:25:45.978419Z","iopub.execute_input":"2024-11-06T13:25:45.979439Z","iopub.status.idle":"2024-11-06T13:25:45.987621Z","shell.execute_reply.started":"2024-11-06T13:25:45.979396Z","shell.execute_reply":"2024-11-06T13:25:45.986697Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Discriminator","metadata":{}},{"cell_type":"code","source":"class BaseDiscriminator(nn.Module):\n    def __init__(self, input_dim=784):\n        super(BaseDiscriminator, self).__init__()\n        # Fully connected layers replacing convolutional layers\n        self.fc1 = nn.Linear(input_dim, 1024)  # input_dim should match the generator's output dimension\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 256)\n        # Final classification layer with spectral normalization\n        self.fc4 = nn.utils.spectral_norm(nn.Linear(256, 1))\n        \n        # Class embedding weights\n        self.use_class = num_class > 0\n\n        # Class-specific weights for feature scaling\n        self.fc_w = nn.Parameter(torch.randn(1, 256))\n\n    def forward(self, x):        \n        # Pass input through the fully connected layers\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        h_feature = F.leaky_relu(self.fc3(x), 0.2)\n        h_feature = torch.flatten(h_feature, start_dim=1)\n        weights = self.fc_w\n        out = (h_feature * weights).sum(dim=1)\n        return out\n\n# Modified Discriminator Architecture\nclass SanDiscriminator(BaseDiscriminator):\n    def __init__(self, num_class=10):\n        super(SanDiscriminator, self).__init__(num_class)\n\n    def forward(self, x, class_ids, flg_train: bool):\n        h_feature = self.h_function(x)\n        h_feature = torch.flatten(h_feature, start_dim=1)\n        weights = self.fc_w[class_ids] if self.use_class else self.fc_w\n        direction = F.normalize(weights, dim=1) # Normalize the last layer\n        scale = torch.norm(weights, dim=1).unsqueeze(1)\n        h_feature = h_feature * scale # For keep the scale\n        if flg_train: # for discriminator training\n            out_fun = (h_feature * direction.detach()).sum(dim=1)\n            out_dir = (h_feature.detach() * direction).sum(dim=1)\n            out = dict(fun=out_fun, dir=out_dir)\n        else: # for generator training or inference\n            out = (h_feature * direction).sum(dim=1)\n\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T13:25:47.85861Z","iopub.execute_input":"2024-11-06T13:25:47.859363Z","iopub.status.idle":"2024-11-06T13:25:47.871958Z","shell.execute_reply.started":"2024-11-06T13:25:47.859325Z","shell.execute_reply":"2024-11-06T13:25:47.870918Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import argparse\nimport json\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport tqdm\n\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T13:25:51.159631Z","iopub.execute_input":"2024-11-06T13:25:51.160157Z","iopub.status.idle":"2024-11-06T13:25:52.259426Z","shell.execute_reply.started":"2024-11-06T13:25:51.160114Z","shell.execute_reply":"2024-11-06T13:25:52.258653Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nimport json\n\n# Define folder paths\nmnist_folder = './data/MNIST'\nlogs_folder = './logs'\nparams_path = './hparams/params.json'\n\n# Create folders if they don't exist\nos.makedirs(mnist_folder, exist_ok=True)\nos.makedirs(logs_folder, exist_ok=True)\nos.makedirs(os.path.dirname(params_path), exist_ok=True)\n\n# Define the parameters for params.json\nparams = {\n    \"dim_latent\": 100,\n    \"batch_size\": 512,\n    \"learning_rate\": 0.0001,\n    \"beta_1\": 0.0,\n    \"beta_2\": 0.99,\n    \"num_epochs\": 400\n}\n\n# Write parameters to params.json\nwith open(params_path, 'w') as f:\n    json.dump(params, f, indent=4)\n\nprint(f\"Created folders '{mnist_folder}' and '{logs_folder}', and saved parameters to '{params_path}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T14:08:34.156336Z","iopub.execute_input":"2024-11-06T14:08:34.156748Z","iopub.status.idle":"2024-11-06T14:08:34.166166Z","shell.execute_reply.started":"2024-11-06T14:08:34.15671Z","shell.execute_reply":"2024-11-06T14:08:34.165147Z"}},"outputs":[{"name":"stdout","text":"Created folders './data/MNIST' and './logs', and saved parameters to './hparams/params.json'.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"default_args = {\n    \"datadir\": \"./data/MNIST\",\n    \"params\": \"./hparams/params.json\",\n    \"model\": \"gan\",\n    \"enable_class\": False,\n    \"logdir\": \"./logs\",\n    \"device\": 0\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T14:08:34.988797Z","iopub.execute_input":"2024-11-06T14:08:34.989225Z","iopub.status.idle":"2024-11-06T14:08:34.994141Z","shell.execute_reply.started":"2024-11-06T14:08:34.989173Z","shell.execute_reply":"2024-11-06T14:08:34.993139Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"from argparse import Namespace\nargs = Namespace(**default_args)\n\nprint(args.datadir)        # Access './data/MNIST'\nprint(args.params)         # Access './hparams/params.json'\nprint(args.model)          # Access 'gan'\nprint(args.enable_class)   # Access False\nprint(args.logdir)         # Access './logs'\nprint(args.device)         # Access 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T14:08:35.710471Z","iopub.execute_input":"2024-11-06T14:08:35.710921Z","iopub.status.idle":"2024-11-06T14:08:35.717171Z","shell.execute_reply.started":"2024-11-06T14:08:35.710884Z","shell.execute_reply":"2024-11-06T14:08:35.716265Z"}},"outputs":[{"name":"stdout","text":"./data/MNIST\n./hparams/params.json\ngan\nFalse\n./logs\n0\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Train functions\n\ndef update_discriminator(x, discriminator, generator, optimizer, params):\n    bs = x.size(0)\n    device = x.device\n\n    optimizer.zero_grad()\n\n    # for data (ground-truth) distribution\n    disc_real = discriminator(x)\n    loss_real = eval('compute_loss_'+args.model)(disc_real, loss_type='real')\n\n    # for generator distribution\n    latent = torch.randn(bs, params[\"dim_latent\"], device=device)\n    img_fake = generator(latent)\n    disc_fake = discriminator(img_fake.detach())\n    loss_fake = eval('compute_loss_'+args.model)(disc_fake, loss_type='fake')\n\n\n    loss_d = loss_real + loss_fake\n    loss_d.backward()\n    optimizer.step()\n    \n    return loss_d\n\n\ndef update_generator(num_class, discriminator, generator, optimizer, params, device):\n    optimizer.zero_grad()\n\n    bs = params['batch_size']\n    latent = torch.randn(bs, params[\"dim_latent\"], device=device)\n\n    batch_fake = generator(latent)\n\n    disc_gen = discriminator(batch_fake)\n    loss_g = - disc_gen.mean()\n    loss_g.backward()\n    optimizer.step()\n\n    return loss_g\n\n\ndef compute_loss_gan(disc, loss_type):\n    assert (loss_type in ['real', 'fake'])\n    if 'real' == loss_type:\n        loss = (1. - disc).relu().mean() # Hinge loss\n    else: # 'fake' == loss_type\n        loss = (1. + disc).relu().mean() # Hinge loss\n\n    return loss\n\n\ndef compute_loss_san(disc, loss_type):\n    assert (loss_type in ['real', 'fake'])\n    if 'real' == loss_type:\n        loss_fun = (1. - disc['fun']).relu().mean() # Hinge loss for function h\n        loss_dir = - disc['dir'].mean() # Wasserstein loss for omega\n    else: # 'fake' == loss_type\n        loss_fun = (1. + disc['fun']).relu().mean() # Hinge loss for function h\n        loss_dir = disc['dir'].mean() # Wasserstein loss for omega\n    loss = loss_fun + loss_dir\n\n    return loss\n\n\ndef save_images(imgs, idx, dirname='test'):\n    # Ensure imgs is a numpy array if it's a tensor\n    if isinstance(imgs, torch.Tensor):\n        imgs = imgs.cpu().data.numpy()\n\n    # If the images are grayscale (1 channel), repeat them to make them RGB (3 channels)\n    if imgs.shape[1] == 1:  # This checks if there is only 1 channel (grayscale)\n        imgs = np.repeat(imgs, 3, axis=1)  # Repeat the grayscale channel 3 times to make RGB\n\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(f'out/{dirname}/'):\n        os.makedirs(f'out/{dirname}/')\n\n    # Set up the plot\n    fig = plt.figure(figsize=(10, 10))\n    gs = gridspec.GridSpec(10, 10)\n    gs.update(wspace=0.05, hspace=0.05)\n\n    # Loop through the batch of images\n    for i, sample in enumerate(imgs):\n        ax = plt.subplot(gs[i])\n        plt.axis('off')\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        ax.set_aspect('equal')\n\n        # Ensure each sample has the shape (height, width, channels) for imshow\n        sample = sample.transpose((1, 2, 0))  # Convert from (C, H, W) -> (H, W, C)\n\n        # Plot the image\n        plt.imshow(sample)\n\n    # Save the plot to the directory\n    plt.savefig(f'out/{dirname}/{str(idx).zfill(3)}.png', bbox_inches=\"tight\")\n    plt.close(fig)\n\ndef plot_generated_images(generator, epoch, num_images=20):\n    \"\"\"Function to plot and display generated images from the generator.\"\"\"\n    generator.eval()\n    with torch.no_grad():\n        noise = torch.randn(num_images, 100).to(device)\n        generated_images = generator(noise)\n        generated_images = generated_images.view(-1, 1, 28, 28).cpu()\n\n        # Create two rows of 10 images\n        fig, axes = plt.subplots(2, 10, figsize=(15, 6))\n        axes = axes.flatten()  # Flatten the axes array for easy iteration\n        for ax, img in zip(axes, generated_images):\n            ax.imshow(img.squeeze(), cmap='gray')\n            ax.axis('off')\n        plt.tight_layout()\n        plt.show()\n\ndef plot_losses(G_losses, D_losses):\n    G_losses = [loss.detach().cpu().numpy() for loss in G_losses]\n    D_losses = [loss.detach().cpu().numpy() for loss in D_losses]\n    \"\"\"Function to plot the losses over epochs.\"\"\"\n    plt.figure(figsize=(10, 5))\n    plt.plot(G_losses, label=\"Generator Loss\")\n    plt.plot(D_losses, label=\"Discriminator Loss\")\n    plt.title(\"Generator and Discriminator Losses Over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T14:08:36.365368Z","iopub.execute_input":"2024-11-06T14:08:36.365731Z","iopub.status.idle":"2024-11-06T14:08:36.388652Z","shell.execute_reply.started":"2024-11-06T14:08:36.365695Z","shell.execute_reply":"2024-11-06T14:08:36.38773Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"device = f'cuda:{args.device}' if args.device is not None else 'cpu'\nmodel_name = args.model\nprint(model_name)\nif not model_name in ['gan', 'san']:\n    raise RuntimeError(\"A model name have to be 'gan' or 'san'.\")\n    \nexperiment_name = model_name + \"_cond\" if args.enable_class else model_name\n\ntransform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\n# dataloading\nnum_class = 10\ntrain_dataset = datasets.MNIST(root=args.datadir, transform=transform, train=True, download=True)\ntrain_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], num_workers=4,\n                          pin_memory=True, persistent_workers=True, shuffle=True)\n\ntest_dataset = datasets.MNIST(root=args.datadir, transform=transform, train=False, download=True)\ntest_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], num_workers=4,\n                         pin_memory=True, persistent_workers=True, shuffle=False)\n\n# model\ngenerator = Generator(g_output_dim=784)\n\nif 'gan' == args.model:\n    discriminator = BaseDiscriminator(input_dim=784)\n    #discriminator = BaseDiscriminator(num_class=num_class if use_class else 0)\nelse: # 'san' == args.model\n    discriminator = SanDiscriminator(num_class=num_class if use_class else 0)\ngenerator = generator.to(device)\ndiscriminator = discriminator.to(device)\n\n# optimizer\nbetas = (params[\"beta_1\"], params[\"beta_2\"])\noptimizer_G = optim.Adam(generator.parameters(), lr=params[\"learning_rate\"], betas=betas)\noptimizer_D = optim.Adam(discriminator.parameters(), lr=params[\"learning_rate\"], betas=betas)\n\nckpt_dir = f'{args.logdir}/{experiment_name}/'\nif not os.path.exists(args.logdir):\n    os.mkdir(args.logdir)\nif not os.path.exists(ckpt_dir):\n    os.mkdir(ckpt_dir)\n\nsteps_per_epoch = len(train_loader)\n\nmsg = [\"\\t{0}: {1}\".format(key, val) for key, val in params.items()]\nprint(\"hyperparameters: \\n\" + \"\\n\".join(msg))\n\n# eval initial states\nnum_samples_per_class = 10\nwith torch.no_grad():\n    latent = torch.randn(num_samples_per_class * num_class, params[\"dim_latent\"]).cuda()\n    imgs_fake = generator(latent)\n\n\nG_losses = []\nD_losses = []\n\n# main training loop\nfor n in range(params[\"num_epochs\"]):\n    loader = iter(train_loader)\n\n    print(\"epoch: {0}/{1}\".format(n + 1, params[\"num_epochs\"]))\n    G_loss_epoch = 0\n    D_loss_epoch = 0\n\n    for i in tqdm.trange(steps_per_epoch):\n        x, class_ids = next(loader)\n        x = x.to(device)\n        x = x.view(x.size(0), -1)\n\n        D_loss = update_discriminator(x, discriminator, generator, optimizer_D, params)\n        G_loss = update_generator(num_class, discriminator, generator, optimizer_G, params, device)\n\n        D_loss_epoch += D_loss\n        G_loss_epoch += G_loss\n\n\n    # Store the average loss per epoch\n    D_losses.append(D_loss_epoch / len(train_loader))\n    G_losses.append(G_loss_epoch / len(train_loader))\n\n    plot_generated_images(generator, n+1)\n    \n    torch.save(generator.state_dict(), ckpt_dir + \"g.\" + str(n) + \".tmp\")\n    torch.save(discriminator.state_dict(), ckpt_dir + \"d.\" + str(n) + \".tmp\")\n\n\n    # eval\n    with torch.no_grad():\n        latent = torch.randn(num_samples_per_class * num_class, params[\"dim_latent\"]).cuda()\n        imgs_fake = generator(latent).cpu().data.numpy()\n        imgs_fake = imgs_fake.reshape(-1, 1, 28, 28)\n        save_images(imgs_fake, n, dirname=experiment_name)\n\n    plot_losses(G_losses, D_losses)\n\ntorch.save(generator.state_dict(), ckpt_dir + \"generator.pt\")\ntorch.save(discriminator.state_dict(), ckpt_dir + \"discriminator.pt\")\n\nplot_losses(G_losses, D_losses)\nprint('Training done')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T14:44:25.353492Z","iopub.execute_input":"2024-11-06T14:44:25.353892Z","iopub.status.idle":"2024-11-06T14:44:31.677322Z","shell.execute_reply.started":"2024-11-06T14:44:25.353853Z","shell.execute_reply":"2024-11-06T14:44:31.676019Z"}},"outputs":[{"name":"stdout","text":"gan\nhyperparameters: \n\tdim_latent: 100\n\tbatch_size: 512\n\tlearning_rate: 0.001\n\tbeta_1: 0.0\n\tbeta_2: 0.99\n\tnum_epochs: 400\nepoch: 1/400\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 1/118 [00:00<00:32,  3.59it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7db07fdc64d0>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n    self._shutdown_workers()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\nException ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7db07fdc64d0>if w.is_alive():\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\nAssertionError    if w.is_alive():: can only test a child process\n\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \nAssertionError: can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7db07fdc64d0>Exception ignored in: \n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n    self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7db07fdc64d0>\n\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n    if w.is_alive():Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n\n    self._shutdown_workers()  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n    if w.is_alive():\n      File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\nassert self._parent_pid == os.getpid(), 'can only test a child process'\nAssertionError: can only test a child process\nAssertionError: can only test a child process\n 47%|████▋     | 56/118 [00:04<00:04, 13.68it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[46], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m D_loss_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtrange(steps_per_epoch):\n\u001b[0;32m---> 69\u001b[0m     x, class_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     71\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1283\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1283\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1285\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":46},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}