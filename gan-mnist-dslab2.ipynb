{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9644358,"sourceType":"datasetVersion","datasetId":5887736},{"sourceId":145569,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":123427,"modelId":139891}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lukalafaye/gan-mnist-dslab2?scriptVersionId=206760576\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# SAN","metadata":{}},{"cell_type":"code","source":"!pip3 install torch tqdm matplotlib pytorch-fid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:37:54.509318Z","iopub.execute_input":"2024-11-12T10:37:54.509662Z","iopub.status.idle":"2024-11-12T10:38:25.036878Z","shell.execute_reply.started":"2024-11-12T10:37:54.509628Z","shell.execute_reply":"2024-11-12T10:38:25.035837Z"}},"outputs":[{"name":"stdout","text":"Collecting torch\n  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.67.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.9.2)\nRequirement already satisfied: pytorch-fid in /opt/conda/lib/python3.10/site-packages (0.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\nCollecting triton==3.1.0 (from torch)\n  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pytorch-fid) (1.14.1)\nRequirement already satisfied: torchvision>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-fid) (0.15.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.2.2->pytorch-fid) (2.32.3)\nCollecting torch\n  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch) (2.0.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (70.0.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.43.0)\nRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.31.0.1)\nRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (18.1.8)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2024.8.30)\nUsing cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\nInstalling collected packages: torch\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-2.0.1\n","output_type":"stream"}],"execution_count":86},{"cell_type":"markdown","source":"# Generator","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np \nfrom torch.nn.utils import spectral_norm\n\nclass Generator(nn.Module):\n    def __init__(self, g_output_dim=784, dim_latent=100):\n        super(Generator, self).__init__()\n        self.fc1 = nn.Linear(100, 256)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        return torch.tanh(self.fc4(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:34.684509Z","iopub.execute_input":"2024-11-12T10:39:34.684933Z","iopub.status.idle":"2024-11-12T10:39:34.695471Z","shell.execute_reply.started":"2024-11-12T10:39:34.684896Z","shell.execute_reply":"2024-11-12T10:39:34.694234Z"}},"outputs":[],"execution_count":87},{"cell_type":"markdown","source":"# Discriminator","metadata":{}},{"cell_type":"code","source":"class BaseDiscriminator(nn.Module):\n    def __init__(self, d_input_dim=784):\n        super(BaseDiscriminator, self).__init__()\n        self.h_function = nn.Sequential(\n            #nn.Linear(d_input_dim, 512),\n            spectral_norm(nn.Linear(d_input_dim, 1024)),\n            nn.LeakyReLU(0.2),\n            #nn.Linear(1024, 512),\n            #nn.LeakyReLU(0.2),\n            #nn.Linear(512, 256),\n            spectral_norm(nn.Linear(1024, 512)),\n            nn.LeakyReLU(0.2),\n            #nn.Linear(256, 1)\n            spectral_norm(nn.Linear(512, 256)),\n            nn.LeakyReLU(0.2),\n        )\n\n        self.fc_w = nn.Parameter(torch.randn(1, 256))\n\n    def forward(self, x, flg_train: bool):        \n        h_feature = self.h_function(x)\n        weights = self.fc_w\n        out = (h_feature * weights).sum(dim=1)\n        return out\n\nclass SanDiscriminator(BaseDiscriminator):\n    def __init__(self, d_input_dim=784):\n        super(SanDiscriminator, self).__init__(d_input_dim)\n\n    def forward(self, x, flg_train: bool):\n        h_feature = self.h_function(x)        \n        weights = self.fc_w\n        direction = F.normalize(weights, dim=1)  # Normalize the last layer\n        scale = torch.norm(weights, dim=1).unsqueeze(1)\n        h_feature = h_feature * scale  # Keep the scale\n        if flg_train:  # For discriminator training\n            out_fun = (h_feature * direction.detach()).sum(dim=1)\n            out_dir = (h_feature.detach() * direction).sum(dim=1)\n            out = dict(fun=out_fun, dir=out_dir)\n        else:  # For generator training or inference\n            out = (h_feature * direction).sum(dim=1)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:34.697399Z","iopub.execute_input":"2024-11-12T10:39:34.697702Z","iopub.status.idle":"2024-11-12T10:39:34.710935Z","shell.execute_reply.started":"2024-11-12T10:39:34.697671Z","shell.execute_reply":"2024-11-12T10:39:34.710003Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"import argparse\nimport json\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport tqdm\n\nfrom torch.utils.data import DataLoader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:34.711933Z","iopub.execute_input":"2024-11-12T10:39:34.7122Z","iopub.status.idle":"2024-11-12T10:39:34.722095Z","shell.execute_reply.started":"2024-11-12T10:39:34.712171Z","shell.execute_reply":"2024-11-12T10:39:34.72134Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"import os\nimport json\n\n# Define folder paths\nmnist_folder = './data/MNIST'\nlogs_folder = './logs'\nparams_path = './hparams/params.json'\n\n# Create folders if they don't exist\nos.makedirs(mnist_folder, exist_ok=True)\nos.makedirs(logs_folder, exist_ok=True)\nos.makedirs(os.path.dirname(params_path), exist_ok=True)\n\n# Define the parameters for params.json\nparams = {\n    \"dim_latent\": 100,\n    \"batch_size\": 128,\n    \"learning_rate_d\": 0.0001,\n    \"learning_rate_g\": 0.0007,    \n    \"beta_1\": 0.5,\n    \"beta_2\": 0.999,\n    \"num_epochs\": 150\n}\n\n# Write parameters to params.json\nwith open(params_path, 'w') as f:\n    json.dump(params, f, indent=4)\n\nprint(f\"Created folders '{mnist_folder}' and '{logs_folder}', and saved parameters to '{params_path}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:34.724487Z","iopub.execute_input":"2024-11-12T10:39:34.725129Z","iopub.status.idle":"2024-11-12T10:39:34.733492Z","shell.execute_reply.started":"2024-11-12T10:39:34.725095Z","shell.execute_reply":"2024-11-12T10:39:34.732543Z"}},"outputs":[{"name":"stdout","text":"Created folders './data/MNIST' and './logs', and saved parameters to './hparams/params.json'.\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"default_args = {\n    \"datadir\": \"./data/MNIST\",\n    \"params\": \"./hparams/params.json\",\n    \"model\": \"san\",\n    \"enable_class\": False,\n    \"logdir\": \"./logs\",\n    \"device\": 0\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:34.734701Z","iopub.execute_input":"2024-11-12T10:39:34.735063Z","iopub.status.idle":"2024-11-12T10:39:34.741791Z","shell.execute_reply.started":"2024-11-12T10:39:34.73502Z","shell.execute_reply":"2024-11-12T10:39:34.740938Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"from argparse import Namespace\nargs = Namespace(**default_args)\n\nprint(args.datadir)        # Access './data/MNIST'\nprint(args.params)         # Access './hparams/params.json'\nprint(args.model)          # Access 'gan'\nprint(args.enable_class)   # Access False\nprint(args.logdir)         # Access './logs'\nprint(args.device)         # Access 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:34.74291Z","iopub.execute_input":"2024-11-12T10:39:34.743242Z","iopub.status.idle":"2024-11-12T10:39:34.751058Z","shell.execute_reply.started":"2024-11-12T10:39:34.743196Z","shell.execute_reply":"2024-11-12T10:39:34.750039Z"}},"outputs":[{"name":"stdout","text":"./data/MNIST\n./hparams/params.json\nsan\nFalse\n./logs\n0\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"# Train functions\n\ndef update_discriminator(x, discriminator, generator, optimizer, params):\n    bs = x.size(0)\n    device = x.device\n\n    optimizer.zero_grad()\n\n    # for data (ground-truth) distribution\n    disc_real = discriminator(x, flg_train=True)\n    loss_real = eval('compute_loss_'+args.model)(disc_real, loss_type='real')\n\n    # for generator distribution\n    latent = torch.randn(bs, params[\"dim_latent\"], device=device)\n    img_fake = generator(latent)\n    disc_fake = discriminator(img_fake.detach(), flg_train=True)\n    loss_fake = eval('compute_loss_'+args.model)(disc_fake, loss_type='fake')\n\n\n    loss_d = loss_real + loss_fake\n    loss_d.backward()\n    optimizer.step()\n    \n    return loss_real, loss_fake\n\ndef update_generator(discriminator, generator, optimizer, params, device):\n    optimizer.zero_grad()\n\n    bs = params['batch_size']\n    latent = torch.randn(bs, params[\"dim_latent\"], device=device)\n\n    batch_fake = generator(latent)\n\n    disc_gen = discriminator(batch_fake, flg_train=False)\n    loss_g = - disc_gen.mean()\n    loss_g.backward()\n    optimizer.step()\n\n    if torch.isnan(loss_g).any():\n        print(\"NaN detected in generator loss!\")\n        return loss_g\n    return loss_g\n    \n\ndef compute_loss_gan(disc, loss_type):\n    assert (loss_type in ['real', 'fake'])\n    if 'real' == loss_type:\n        loss = (1. - disc).relu().mean() # Hinge loss\n    else: # 'fake' == loss_type\n        loss = (1. + disc).relu().mean() # Hinge loss\n\n    return loss\n\n\ndef compute_loss_san(disc, loss_type):\n    assert (loss_type in ['real', 'fake'])\n    if 'real' == loss_type:\n        loss_fun = (1. - disc['fun']).relu().mean() # Hinge loss for function h\n        loss_dir = - disc['dir'].mean() # Wasserstein loss for omega\n    else: # 'fake' == loss_type\n        loss_fun = (1. + disc['fun']).relu().mean() # Hinge loss for function h\n        loss_dir = disc['dir'].mean() # Wasserstein loss for omega\n\n    lambd = 1\n    loss = loss_fun + lambd * loss_dir\n\n    return loss\n\n\ndef save_images(imgs, idx, dirname='test'):\n    # Ensure imgs is a numpy array if it's a tensor\n    if isinstance(imgs, torch.Tensor):\n        imgs = imgs.cpu().data.numpy()\n\n    # If the images are grayscale (1 channel), repeat them to make them RGB (3 channels)\n    if imgs.shape[1] == 1:  # This checks if there is only 1 channel (grayscale)\n        imgs = np.repeat(imgs, 3, axis=1)  # Repeat the grayscale channel 3 times to make RGB\n\n    # Create the output directory if it doesn't exist\n    if not os.path.exists(f'out/{dirname}/'):\n        os.makedirs(f'out/{dirname}/')\n\n    # Set up the plot\n    fig = plt.figure(figsize=(10, 10))\n    gs = gridspec.GridSpec(10, 10)\n    gs.update(wspace=0.05, hspace=0.05)\n\n    # Loop through the batch of images\n    for i, sample in enumerate(imgs):\n        ax = plt.subplot(gs[i])\n        plt.axis('off')\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        ax.set_aspect('equal')\n\n        # Ensure each sample has the shape (height, width, channels) for imshow\n        sample = sample.transpose((1, 2, 0))  # Convert from (C, H, W) -> (H, W, C)\n\n        # Plot the image\n        plt.imshow(sample)\n\n    # Save the plot to the directory\n    plt.savefig(f'out/{dirname}/{str(idx).zfill(3)}.png', bbox_inches=\"tight\")\n    plt.close(fig)\n\ndef plot_generated_images(generator, epoch, num_images=20):\n    \"\"\"Function to plot and display generated images from the generator.\"\"\"\n    generator.eval()\n    with torch.no_grad():\n        noise = torch.randn(num_images, 100).to(device)\n        generated_images = generator(noise)\n        generated_images = generated_images.view(-1, 1, 28, 28).cpu()\n\n        # Create two rows of 10 images\n        fig, axes = plt.subplots(2, 10, figsize=(15, 6))\n        axes = axes.flatten()  # Flatten the axes array for easy iteration\n        for ax, img in zip(axes, generated_images):\n            ax.imshow(img.squeeze(), cmap='gray')\n            ax.axis('off')\n        plt.tight_layout()\n        plt.show()\n\ndef plot_losses(G_losses, D_real_losses, D_fake_losses):\n    G_losses = [loss.detach().cpu().numpy() for loss in G_losses]\n    D_real_losses = [loss.detach().cpu().numpy() for loss in D_real_losses]\n    D_fake_losses = [loss.detach().cpu().numpy() for loss in D_fake_losses]\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(G_losses, label=\"Generator Loss\")\n    plt.plot(D_real_losses, label=\"Discriminator Real Loss\")\n    plt.plot(D_fake_losses, label=\"Discriminator Fake Loss\")\n    \n    plt.title(\"Generator and Discriminator Losses Over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    \n    plt.ylim(-5, 5)\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:34.786956Z","iopub.execute_input":"2024-11-12T10:39:34.787259Z","iopub.status.idle":"2024-11-12T10:39:34.816386Z","shell.execute_reply.started":"2024-11-12T10:39:34.787227Z","shell.execute_reply":"2024-11-12T10:39:34.815288Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = f'cuda:{args.device}' if args.device is not None else 'cpu'\nmodel_name = args.model\nprint(model_name)\nif not model_name in ['gan', 'san']:\n    raise RuntimeError(\"A model name have to be 'gan' or 'san'.\")\n    \nexperiment_name = model_name + \"_cond\" if args.enable_class else model_name\n\ntransform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\n# dataloading\nnum_class = 10\ntrain_dataset = datasets.MNIST(root=args.datadir, transform=transform, train=True, download=True)\ntrain_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], num_workers=8,\n                          pin_memory=True, persistent_workers=True, shuffle=True)\n\ntest_dataset = datasets.MNIST(root=args.datadir, transform=transform, train=False, download=True)\ntest_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], num_workers=8,\n                         pin_memory=True, persistent_workers=True, shuffle=False)\n\n# model\ngenerator = Generator(g_output_dim=784)\n\nif 'gan' == args.model:\n    discriminator = BaseDiscriminator(d_input_dim=784)\nelse: # 'san' == args.model\n    discriminator = SanDiscriminator(d_input_dim=784)\ngenerator = generator.to(device)\ndiscriminator = discriminator.to(device)\n\n# optimizer\nbetas = (params[\"beta_1\"], params[\"beta_2\"])\noptimizer_G = optim.Adam(generator.parameters(), lr=params[\"learning_rate_g\"], betas=betas)\noptimizer_D = optim.Adam(discriminator.parameters(), lr=params[\"learning_rate_d\"], betas=betas)\n\nckpt_dir = f'{args.logdir}/{experiment_name}/'\nif not os.path.exists(args.logdir):\n    os.mkdir(args.logdir)\nif not os.path.exists(ckpt_dir):\n    os.mkdir(ckpt_dir)\n\nsteps_per_epoch = len(train_loader)\n\nmsg = [\"\\t{0}: {1}\".format(key, val) for key, val in params.items()]\nprint(\"hyperparameters: \\n\" + \"\\n\".join(msg))\n\n# eval initial states\nnum_samples_per_class = 10\nwith torch.no_grad():\n    latent = torch.randn(num_samples_per_class * num_class, params[\"dim_latent\"]).cuda()\n    imgs_fake = generator(latent)\n\n\nG_losses = []\nD_real_losses = []\nD_fake_losses = [] \n\n# main training loop\nfor n in range(params[\"num_epochs\"]):\n    loader = iter(train_loader)\n\n    print(\"epoch: {0}/{1}\".format(n + 1, params[\"num_epochs\"]))\n    G_loss_epoch = 0\n    D_real_loss_epoch = 0\n    D_fake_loss_epoch = 0\n\n    for i in tqdm.trange(steps_per_epoch):\n        x, class_ids = next(loader)\n        x = x.to(device)\n        x = x.view(x.size(0), -1)\n\n        loss_real, loss_fake = update_discriminator(x, discriminator, generator, optimizer_D, params)\n        G_loss = update_generator(discriminator, generator, optimizer_G, params, device)\n\n        D_real_loss_epoch += loss_real\n        D_fake_loss_epoch += loss_fake\n        G_loss_epoch += G_loss\n\n\n    # Store the average loss per epoch\n    print(\"D-real:\", D_real_loss_epoch / len(train_loader))\n    print(\"D-fake:\", D_fake_loss_epoch / len(train_loader))\n    print(\"G-fake:\", G_loss_epoch / len(train_loader))\n    \n    D_real_losses.append(D_real_loss_epoch / len(train_loader))\n    D_fake_losses.append(D_fake_loss_epoch / len(train_loader))\n    \n    G_losses.append(G_loss_epoch / len(train_loader))\n    \n\n    plot_generated_images(generator, n+1)\n    \n    torch.save(generator.state_dict(), ckpt_dir + \"g.\" + str(n) + \".tmp\")\n    torch.save(discriminator.state_dict(), ckpt_dir + \"d.\" + str(n) + \".tmp\")\n\n\n    # eval\n    with torch.no_grad():\n        latent = torch.randn(num_samples_per_class * num_class, params[\"dim_latent\"]).cuda()\n        imgs_fake = generator(latent).cpu().data.numpy()\n        imgs_fake = imgs_fake.reshape(-1, 1, 28, 28)\n        save_images(imgs_fake, n, dirname=experiment_name)\n\n    plot_losses(G_losses, D_real_losses, D_fake_losses)\n\ntorch.save(generator.state_dict(), ckpt_dir + \"generator.pt\")\ntorch.save(discriminator.state_dict(), ckpt_dir + \"discriminator.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:34.818102Z","iopub.execute_input":"2024-11-12T10:39:34.818953Z","iopub.status.idle":"2024-11-12T10:39:47.473819Z","shell.execute_reply.started":"2024-11-12T10:39:34.818918Z","shell.execute_reply":"2024-11-12T10:39:47.471411Z"}},"outputs":[{"name":"stdout","text":"san\nhyperparameters: \n\tdim_latent: 100\n\tbatch_size: 128\n\tlearning_rate_d: 0.0001\n\tlearning_rate_g: 0.0007\n\tbeta_1: 0.5\n\tbeta_2: 0.999\n\tnum_epochs: 150\nepoch: 1/150\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/469 [00:00<?, ?it/s]Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\nModuleNotFoundError: No module named 'torch.nested._internal'\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\nModuleNotFoundError: No module named 'torch.nested._internal'\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\nModuleNotFoundError: No module named 'torch.nested._internal'\nTraceback (most recent call last):\nModuleNotFoundError: No module named 'torch.nested._internal'\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\nTraceback (most recent call last):\nModuleNotFoundError: No module named 'torch.nested._internal'\nModuleNotFoundError: No module named 'torch.nested._internal'\nModuleNotFoundError: No module named 'torch.nested._internal'\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\nModuleNotFoundError: No module named 'torch.nested._internal'\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\nModuleNotFoundError: No module named 'torch.nested._internal'\nModuleNotFoundError: No module named 'torch.nested._internal'\nTraceback (most recent call last):\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nModuleNotFoundError: No module named 'torch.nested._internal'\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\nModuleNotFoundError: No module named 'torch.nested._internal'\nModuleNotFoundError: No module named 'torch.nested._internal'\nModuleNotFoundError: No module named 'torch.nested._internal'\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\nModuleNotFoundError: No module named 'torch.nested._internal'\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 296, in reduce_tensor\n    return (stat.st_ino, stat.st_dev)\nModuleNotFoundError: No module named 'torch.nested._internal'\n  0%|          | 0/469 [00:11<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[94], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m D_fake_loss_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtrange(steps_per_epoch):\n\u001b[0;32m---> 70\u001b[0m     x, class_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     72\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[0;32m--> 630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m    633\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m-> 1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1283\u001b[0m, in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader timed out after \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout))\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m   1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n","File \u001b[0;32m/opt/conda/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":94},{"cell_type":"markdown","source":"## Generate more samples","metadata":{}},{"cell_type":"code","source":"import torchvision\n\nmodel = torch.nn.DataParallel(generator).cuda()\nmodel.eval()\n\nprint('Model loaded.')\n\n\nprint('Start Generating')\nos.makedirs('samples', exist_ok=True)\n\nimage_paths = []\nbatch_size = params[\"batch_size\"]\ndim_latent = params[\"dim_latent\"]\n\nn_samples = 0\nwith torch.no_grad():\n    while n_samples<10000:\n        z = torch.randn(batch_size, dim_latent).cuda()\n        x = model(z)\n        x = x.reshape(batch_size, 28, 28)\n        for k in range(x.shape[0]):\n            if n_samples<10000:\n                image_path = os.path.join('samples', f'{n_samples}.png')\n                torchvision.utils.save_image(x[k:k+1], image_path)         \n                image_paths.append(image_path)  # Store image path\n                n_samples += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:47.47494Z","iopub.status.idle":"2024-11-12T10:39:47.475343Z","shell.execute_reply.started":"2024-11-12T10:39:47.475127Z","shell.execute_reply":"2024-11-12T10:39:47.475145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import display, Image\n\nfor img_path in image_paths[:10]:  # Slice to get only the first 10 images\n    display(Image(filename=img_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:47.476601Z","iopub.status.idle":"2024-11-12T10:39:47.47696Z","shell.execute_reply.started":"2024-11-12T10:39:47.476786Z","shell.execute_reply":"2024-11-12T10:39:47.476805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:47.478602Z","iopub.status.idle":"2024-11-12T10:39:47.478959Z","shell.execute_reply.started":"2024-11-12T10:39:47.478784Z","shell.execute_reply":"2024-11-12T10:39:47.478803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Directory to save images\nmnist_image_dir = 'MNIST_images'\nos.makedirs(mnist_image_dir, exist_ok=True)\n\n# Define the inverse transform to unnormalize the images\ninv_transform = transforms.Compose([\n    transforms.Normalize(mean=[-1.0], std=[2.0])  # Undo the normalization (0.5 mean, 0.5 std)\n])\n\n# Save each image\nfor i, (image, _) in enumerate(test_dataset):\n    # Inverse normalize and convert to PIL format\n    image = inv_transform(image)\n    image = transforms.ToPILImage()(image)\n    \n    # Save as PNG\n    image.save(os.path.join(mnist_image_dir, f\"image_{i}.png\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:47.480903Z","iopub.status.idle":"2024-11-12T10:39:47.481619Z","shell.execute_reply.started":"2024-11-12T10:39:47.481339Z","shell.execute_reply":"2024-11-12T10:39:47.481369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -1 MNIST_images | wc -l","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:47.483531Z","iopub.status.idle":"2024-11-12T10:39:47.483906Z","shell.execute_reply.started":"2024-11-12T10:39:47.483722Z","shell.execute_reply":"2024-11-12T10:39:47.48374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip installtorch==2.0.1 torchvision torchaudio","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python -m pytorch_fid samples .MNIST_images --device cuda:0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:47.48492Z","iopub.status.idle":"2024-11-12T10:39:47.485281Z","shell.execute_reply.started":"2024-11-12T10:39:47.485078Z","shell.execute_reply":"2024-11-12T10:39:47.485095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nprint(torch.__version__)\nprint(torch.version.cuda)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:47.486707Z","iopub.status.idle":"2024-11-12T10:39:47.487066Z","shell.execute_reply.started":"2024-11-12T10:39:47.48688Z","shell.execute_reply":"2024-11-12T10:39:47.486899Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvcc --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T10:39:47.488453Z","iopub.status.idle":"2024-11-12T10:39:47.488778Z","shell.execute_reply.started":"2024-11-12T10:39:47.488612Z","shell.execute_reply":"2024-11-12T10:39:47.488629Z"}},"outputs":[],"execution_count":null}]}