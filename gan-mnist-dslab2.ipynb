{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9644358,"sourceType":"datasetVersion","datasetId":5887736},{"sourceId":145569,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":123427,"modelId":139891}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lukalafaye/gan-mnist-dslab2?scriptVersionId=205559276\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nos.environ['PYTHON_PATH'] = \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2024-11-01T14:59:10.488361Z","iopub.execute_input":"2024-11-01T14:59:10.488643Z","iopub.status.idle":"2024-11-01T14:59:10.498131Z","shell.execute_reply.started":"2024-11-01T14:59:10.48861Z","shell.execute_reply":"2024-11-01T14:59:10.497291Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\n\n# Specify the device (GPU or CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef D_train(x, G, D, D_optimizer, criterion):\n    #======================= Train the discriminator =======================#\n    D.zero_grad()\n\n    # Train discriminator on real data\n    x_real = x.to(device)\n    y_real = torch.ones(x_real.shape[0], 1, device=device)\n\n    D_output = D(x_real)\n    D_real_loss = criterion(D_output, y_real)\n    D_real_score = D_output\n\n    # Train discriminator on fake data\n    z = torch.randn(x_real.shape[0], 100, device=device)  # Latent vector\n    x_fake = G(z)\n    y_fake = torch.zeros(x_real.shape[0], 1, device=device)\n\n    D_output = D(x_fake)\n\n    D_fake_loss = criterion(D_output, y_fake)\n    D_fake_score = D_output\n\n    # Gradient backpropagation & optimize ONLY D's parameters\n    D_loss = D_real_loss + D_fake_loss\n    D_loss.backward()\n    D_optimizer.step()\n        \n    return D_loss.item(), D_real_score, D_fake_score  # Return scores for analysis\n\n\ndef G_train(x, G, D, G_optimizer, criterion):\n    #======================= Train the generator =======================#\n    G.zero_grad()\n\n    z = torch.randn(x.shape[0], 100, device=device)  # Latent vector\n    y = torch.ones(z.shape[0], 1, device=device)  # Target for generator\n\n    G_output = G(z)\n    D_output = D(G_output)\n    G_loss = criterion(D_output, y)\n\n    # Gradient backpropagation & optimize ONLY G's parameters\n    G_loss.backward()\n    G_optimizer.step()\n        \n    return G_loss.item(), D_output  # Return D_output for analysis\n\n\ndef save_models(G, D, folder):\n    os.makedirs(folder, exist_ok=True)  # Ensure the folder exists\n    torch.save(G.state_dict(), os.path.join(folder, 'G.pth'))\n    torch.save(D.state_dict(), os.path.join(folder, 'D.pth'))\n\n\ndef load_model(model, folder, is_generator=True):\n    model_type = 'G' if is_generator else 'D'\n    ckpt = torch.load(os.path.join(folder, f'{model_type}.pth'), map_location=device)  # Load model to the correct device\n    model.load_state_dict({k.replace('module.', ''): v for k, v in ckpt.items()})\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-01T14:59:48.820722Z","iopub.execute_input":"2024-11-01T14:59:48.821103Z","iopub.status.idle":"2024-11-01T14:59:51.978184Z","shell.execute_reply.started":"2024-11-01T14:59:48.821063Z","shell.execute_reply":"2024-11-01T14:59:51.977232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Generator(nn.Module):\n    def __init__(self, g_output_dim):\n        super(Generator, self).__init__()       \n        self.fc1 = nn.Linear(100, 256)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features * 2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features * 2)\n        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n\n    def forward(self, x): \n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        return torch.tanh(self.fc4(x))\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, d_input_dim):\n        super(SanDiscriminator, self).__init__()\n        self.fc1 = nn.Linear(d_input_dim, 1024)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features // 2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features // 2)\n        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n        \n        # Self-attention inspired parameters\n        self.attention_weights = nn.Parameter(torch.randn(1, self.fc3.out_features))\n\n    def forward(self, x):\n        # Extract features through fully connected layers\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        x = torch.sigmoid(self.fc4(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T14:59:59.733258Z","iopub.execute_input":"2024-11-01T14:59:59.733961Z","iopub.status.idle":"2024-11-01T14:59:59.746408Z","shell.execute_reply.started":"2024-11-01T14:59:59.733922Z","shell.execute_reply":"2024-11-01T14:59:59.745531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch \nimport torchvision\nimport os\nimport argparse","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-01T15:00:05.560833Z","iopub.execute_input":"2024-11-01T15:00:05.561692Z","iopub.status.idle":"2024-11-01T15:00:06.676421Z","shell.execute_reply.started":"2024-11-01T15:00:05.56163Z","shell.execute_reply":"2024-11-01T15:00:06.675473Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args = argparse.Namespace(batch_size=20)  # Set default value\n\nprint('Model Loading...')\n# Model Pipeline\nmnist_dim = 784\n\nmodel = Generator(g_output_dim = mnist_dim).cuda()\nmodel = load_model(model, '/kaggle/input/g/pytorch/v2/1/')\nmodel = torch.nn.DataParallel(model).cuda()\nmodel.eval()\n\nprint('Model loaded.')\n\n\nprint('Start Generating')\nos.makedirs('samples', exist_ok=True)\n\nimage_paths = []\n\nn_samples = 0\nwith torch.no_grad():\n    while n_samples<10000:\n        z = torch.randn(args.batch_size, 100).cuda()\n        x = model(z)\n        x = x.reshape(args.batch_size, 28, 28)\n        for k in range(x.shape[0]):\n            if n_samples<10000:\n                image_path = os.path.join('samples', f'{n_samples}.png')\n                torchvision.utils.save_image(x[k:k+1], image_path)         \n                image_paths.append(image_path)  # Store image path\n                n_samples += 1","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:09.451836Z","iopub.execute_input":"2024-11-01T15:00:09.452635Z","iopub.status.idle":"2024-11-01T15:00:16.476086Z","shell.execute_reply.started":"2024-11-01T15:00:09.452596Z","shell.execute_reply":"2024-11-01T15:00:16.475119Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import display, Image\n\nfor img_path in image_paths[:50]:  # Slice to get only the first 10 images\n    display(Image(filename=img_path))","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:18.957416Z","iopub.execute_input":"2024-11-01T15:00:18.958387Z","iopub.status.idle":"2024-11-01T15:00:19.056568Z","shell.execute_reply.started":"2024-11-01T15:00:18.958332Z","shell.execute_reply":"2024-11-01T15:00:19.055706Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:22.633304Z","iopub.execute_input":"2024-11-01T15:00:22.633909Z","iopub.status.idle":"2024-11-01T15:00:22.63818Z","shell.execute_reply.started":"2024-11-01T15:00:22.633869Z","shell.execute_reply":"2024-11-01T15:00:22.637156Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\nfrom tqdm import trange\nimport argparse\nfrom torchvision import datasets, transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom model import Generator, Discriminator\nfrom utils import D_train, G_train, save_models\nfrom IPython.display import display \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nparser = argparse.ArgumentParser(description='Train Normalizing Flow.')\nparser.add_argument(\"--epochs\", type=int, default=400, help=\"Number of epochs for training.\")\nparser.add_argument(\"--lr\", type=float, default=0.0001, help=\"The learning rate to use for training.\")\nparser.add_argument(\"--batch_size\", type=int, default=1024, help=\"Size of mini-batches for SGD\")\nargs = parser.parse_args(args=[])\n\nos.makedirs('checkpoints', exist_ok=True)\nos.makedirs('data', exist_ok=True)\n\nprint('Dataset loading...')\ntransform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\ntrain_dataset = datasets.MNIST(root='data/MNIST/', train=True, transform=transform, download=True)\ntest_dataset = datasets.MNIST(root='data/MNIST/', train=False, transform=transform, download=False)\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                           batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n                                          batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True)\nprint('Dataset Loaded.')\n\nprint('Model Loading...')\nmnist_dim = 784\nG = torch.nn.DataParallel(Generator(g_output_dim=mnist_dim)).to(device)\nD = torch.nn.DataParallel(Discriminator(mnist_dim)).to(device)\nprint('Model loaded.')\n\ncriterion = nn.BCELoss().to(device)\nG_optimizer = optim.Adam(G.parameters(), lr=args.lr)\nD_optimizer = optim.Adam(D.parameters(), lr=args.lr)\n\nprint('Start Training:')\n\ndef plot_generated_images(generator, epoch, num_images=20):\n    \"\"\"Function to plot and display generated images from the generator.\"\"\"\n    generator.eval()\n    with torch.no_grad():\n        noise = torch.randn(num_images, 100).to(device)\n        generated_images = generator(noise)\n        generated_images = generated_images.view(-1, 1, 28, 28).cpu()\n\n        # Create two rows of 10 images\n        fig, axes = plt.subplots(2, 10, figsize=(15, 6))\n        axes = axes.flatten()  # Flatten the axes array for easy iteration\n        for ax, img in zip(axes, generated_images):\n            ax.imshow(img.squeeze(), cmap='gray')\n            ax.axis('off')\n        plt.tight_layout()\n        plt.show()\n\ndef plot_losses(G_losses, D_losses):\n    \"\"\"Function to plot the losses over epochs.\"\"\"\n    plt.figure(figsize=(10, 5))\n    plt.plot(G_losses, label=\"Generator Loss\")\n    plt.plot(D_losses, label=\"Discriminator Loss\")\n    plt.title(\"Generator and Discriminator Losses Over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\n\n# Initialize lists to store the losses\nG_losses = []\nD_losses = []\n\nn_epoch = args.epochs\nfor epoch in trange(1, n_epoch + 1, leave=True):\n    print(epoch)\n    G_loss_epoch = 0\n    D_loss_epoch = 0\n    \n    for batch_idx, (x, _) in enumerate(train_loader):\n        x = x.view(-1, mnist_dim).to(device)\n        \n        D_loss, _, _ = D_train(x, G, D, D_optimizer, criterion)  # Capture only the first return value\n        G_loss, _ = G_train(x, G, D, G_optimizer, criterion)  # Capture only the first return value\n\n        # Accumulate the losses for the current epoch\n        D_loss_epoch += D_loss\n        G_loss_epoch += G_loss\n\n    # Store the average loss per epoch\n    D_losses.append(D_loss_epoch / len(train_loader))\n    G_losses.append(G_loss_epoch / len(train_loader))\n\n    print(f\"Epoch [{epoch}/{n_epoch}], D Loss: {D_losses[-1]:.4f}, G Loss: {G_losses[-1]:.4f}\")\n\n    # Save models and generate images every 10 epochs\n    if epoch % 10 == 0:\n        save_models(G, D, 'checkpoints')\n        plot_generated_images(G, epoch)\n\n# After training, plot the losses\nplot_losses(G_losses, D_losses)\n\nprint('Training done')","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:00:29.956356Z","iopub.execute_input":"2024-11-01T15:00:29.9571Z","iopub.status.idle":"2024-11-01T15:39:02.826613Z","shell.execute_reply.started":"2024-11-01T15:00:29.957039Z","shell.execute_reply":"2024-11-01T15:39:02.825489Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls checkpoints","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:54:31.632527Z","iopub.execute_input":"2024-11-01T15:54:31.633368Z","iopub.status.idle":"2024-11-01T15:54:32.641225Z","shell.execute_reply.started":"2024-11-01T15:54:31.633312Z","shell.execute_reply":"2024-11-01T15:54:32.640045Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_models(generator, discriminator, epoch, g_losses, d_losses, path='checkpoints'):\n    checkpoint = {\n        'epoch': epoch,\n        'G_state_dict': generator.state_dict(),\n        'D_state_dict': discriminator.state_dict(),\n        'G_optimizer_state_dict': G_optimizer.state_dict(),\n        'D_optimizer_state_dict': D_optimizer.state_dict(),\n        'G_losses': g_losses,\n        'D_losses': d_losses\n    }\n    torch.save(checkpoint, os.path.join(path, 'model_checkpoint.pth'))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:54:33.398018Z","iopub.execute_input":"2024-11-01T15:54:33.398465Z","iopub.status.idle":"2024-11-01T15:54:33.405294Z","shell.execute_reply.started":"2024-11-01T15:54:33.398423Z","shell.execute_reply":"2024-11-01T15:54:33.40421Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_models(generator, discriminator, epoch, g_losses, d_losses)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T15:54:35.252957Z","iopub.execute_input":"2024-11-01T15:54:35.253359Z","iopub.status.idle":"2024-11-01T15:54:35.580072Z","shell.execute_reply.started":"2024-11-01T15:54:35.25332Z","shell.execute_reply":"2024-11-01T15:54:35.578907Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_checkpoint(generator, discriminator, g_optimizer, d_optimizer, path='checkpoints/model_checkpoint.pth'):\n    checkpoint = torch.load(path)\n    generator.load_state_dict(checkpoint['G_state_dict'])\n    discriminator.load_state_dict(checkpoint['D_state_dict'])\n    g_optimizer.load_state_dict(checkpoint['G_optimizer_state_dict'])\n    d_optimizer.load_state_dict(checkpoint['D_optimizer_state_dict'])\n    start_epoch = checkpoint['epoch'] + 1\n    g_losses = checkpoint['G_losses']\n    d_losses = checkpoint['D_losses']\n    return start_epoch, g_losses, d_losses\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.396905Z","iopub.status.idle":"2024-10-27T17:02:17.397277Z","shell.execute_reply.started":"2024-10-27T17:02:17.397077Z","shell.execute_reply":"2024-10-27T17:02:17.397114Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if a checkpoint exists to resume from\ncheckpoint_path = 'checkpoints/model_checkpoint.pth'\nif os.path.exists(checkpoint_path):\n    print(\"Loading checkpoint...\")\n    start_epoch, G_losses, D_losses = load_checkpoint(G, D, G_optimizer, D_optimizer, checkpoint_path)\n    print(f\"Resuming from epoch {start_epoch}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.398682Z","iopub.status.idle":"2024-10-27T17:02:17.399054Z","shell.execute_reply.started":"2024-10-27T17:02:17.398878Z","shell.execute_reply":"2024-10-27T17:02:17.398898Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_epoch=30\nfor epoch in trange(1, n_epoch + 1, leave=True):\n    print(epoch)\n    G_loss_epoch = 0\n    D_loss_epoch = 0\n    \n    for batch_idx, (x, _) in enumerate(train_loader):\n        x = x.view(-1, mnist_dim).to(device)\n        \n        D_loss, _, _ = D_train(x, G, D, D_optimizer, criterion)  # Capture only the first return value\n        G_loss, _ = G_train(x, G, D, G_optimizer, criterion)  # Capture only the first return value\n\n        # Accumulate the losses for the current epoch\n        D_loss_epoch += D_loss\n        G_loss_epoch += G_loss\n\n    # Store the average loss per epoch\n    D_losses.append(D_loss_epoch / len(train_loader))\n    G_losses.append(G_loss_epoch / len(train_loader))\n\n    print(f\"Epoch [{epoch}/{n_epoch}], D Loss: {D_losses[-1]:.4f}, G Loss: {G_losses[-1]:.4f}\")\n\n    # Save models and generate images every 10 epochs\n    if epoch % 10 == 0:\n        save_models(G, D, 'checkpoints')\n        plot_generated_images(G, epoch)\n\n# After training, plot the losses\nplot_losses(G_losses, D_losses)\n\nprint('Training done')","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.400518Z","iopub.status.idle":"2024-10-27T17:02:17.400886Z","shell.execute_reply.started":"2024-10-27T17:02:17.400699Z","shell.execute_reply":"2024-10-27T17:02:17.400724Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(G.state_dict(), 'generator2.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:02:17.402246Z","iopub.status.idle":"2024-10-27T17:02:17.402704Z","shell.execute_reply.started":"2024-10-27T17:02:17.402464Z","shell.execute_reply":"2024-10-27T17:02:17.402488Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch torchvision tqdm matplotlib","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Generator(nn.Module):\n    def __init__(self, g_output_dim=784, dim_latent=100):\n        super(Generator, self).__init__()\n        self.fc1 = nn.Linear(100, 256)\n        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n\n    def forward(self, x):\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        x = F.leaky_relu(self.fc3(x), 0.2)\n        return torch.tanh(self.fc4(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:38:17.7936Z","iopub.execute_input":"2024-11-06T10:38:17.793895Z","iopub.status.idle":"2024-11-06T10:38:23.544643Z","shell.execute_reply.started":"2024-11-06T10:38:17.793863Z","shell.execute_reply":"2024-11-06T10:38:23.543506Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class BaseDiscriminator(nn.Module):\n    def __init__(self, input_dim=784):\n        super(BaseDiscriminator, self).__init__()\n        # Fully connected layers replacing convolutional layers\n        self.fc1 = nn.Linear(input_dim, 1024)  # input_dim should match the generator's output dimension\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 256)\n        # Final classification layer with spectral normalization\n        self.fc4 = nn.utils.spectral_norm(nn.Linear(256, 1))\n        \n        # Class embedding weights\n        self.use_class = num_class > 0\n\n        # Class-specific weights for feature scaling\n        self.fc_w = nn.Parameter(torch.randn(1, 256))\n\n    def forward(self, x):        \n        # Pass input through the fully connected layers\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.leaky_relu(self.fc2(x), 0.2)\n        h_feature = F.leaky_relu(self.fc3(x), 0.2)\n        h_feature = torch.flatten(h_feature, start_dim=1)\n        weights = self.fc_w\n        out = (h_feature * weights).sum(dim=1)\n        return out\n\n# Modified Discriminator Architecture\nclass SanDiscriminator(BaseDiscriminator):\n    def __init__(self, num_class=10):\n        super(SanDiscriminator, self).__init__(num_class)\n\n    def forward(self, x, class_ids, flg_train: bool):\n        h_feature = self.h_function(x)\n        h_feature = torch.flatten(h_feature, start_dim=1)\n        weights = self.fc_w[class_ids] if self.use_class else self.fc_w\n        direction = F.normalize(weights, dim=1) # Normalize the last layer\n        scale = torch.norm(weights, dim=1).unsqueeze(1)\n        h_feature = h_feature * scale # For keep the scale\n        if flg_train: # for discriminator training\n            out_fun = (h_feature * direction.detach()).sum(dim=1)\n            out_dir = (h_feature.detach() * direction).sum(dim=1)\n            out = dict(fun=out_fun, dir=out_dir)\n        else: # for generator training or inference\n            out = (h_feature * direction).sum(dim=1)\n\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:46:19.822995Z","iopub.execute_input":"2024-11-06T10:46:19.82353Z","iopub.status.idle":"2024-11-06T10:46:19.842097Z","shell.execute_reply.started":"2024-11-06T10:46:19.823464Z","shell.execute_reply":"2024-11-06T10:46:19.841018Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import argparse\nimport json\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport tqdm\n\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:46:21.304001Z","iopub.execute_input":"2024-11-06T10:46:21.3045Z","iopub.status.idle":"2024-11-06T10:46:21.312555Z","shell.execute_reply.started":"2024-11-06T10:46:21.304447Z","shell.execute_reply":"2024-11-06T10:46:21.311297Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import os\nimport json\n\n# Define folder paths\nmnist_folder = './data/MNIST'\nlogs_folder = './logs'\nparams_path = './hparams/params.json'\n\n# Create folders if they don't exist\nos.makedirs(mnist_folder, exist_ok=True)\nos.makedirs(logs_folder, exist_ok=True)\nos.makedirs(os.path.dirname(params_path), exist_ok=True)\n\n# Define the parameters for params.json\nparams = {\n    \"dim_latent\": 100,\n    \"batch_size\": 128,\n    \"learning_rate\": 0.001,\n    \"beta_1\": 0.0,\n    \"beta_2\": 0.99,\n    \"num_epochs\": 2\n}\n\n# Write parameters to params.json\nwith open(params_path, 'w') as f:\n    json.dump(params, f, indent=4)\n\nprint(f\"Created folders '{mnist_folder}' and '{logs_folder}', and saved parameters to '{params_path}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:46:22.122406Z","iopub.execute_input":"2024-11-06T10:46:22.122792Z","iopub.status.idle":"2024-11-06T10:46:22.131825Z","shell.execute_reply.started":"2024-11-06T10:46:22.122755Z","shell.execute_reply":"2024-11-06T10:46:22.130843Z"}},"outputs":[{"name":"stdout","text":"Created folders './data/MNIST' and './logs', and saved parameters to './hparams/params.json'.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"default_args = {\n    \"datadir\": \"./data/MNIST\",\n    \"params\": \"./hparams/params.json\",\n    \"model\": \"gan\",\n    \"enable_class\": False,\n    \"logdir\": \"./logs\",\n    \"device\": 0\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:38:26.205343Z","iopub.execute_input":"2024-11-06T10:38:26.206001Z","iopub.status.idle":"2024-11-06T10:38:26.213723Z","shell.execute_reply.started":"2024-11-06T10:38:26.205956Z","shell.execute_reply":"2024-11-06T10:38:26.212842Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from argparse import Namespace\nargs = Namespace(**default_args)\n\nprint(args.datadir)        # Access './data/MNIST'\nprint(args.params)         # Access './hparams/params.json'\nprint(args.model)          # Access 'gan'\nprint(args.enable_class)   # Access False\nprint(args.logdir)         # Access './logs'\nprint(args.device)         # Access 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:46:23.529017Z","iopub.execute_input":"2024-11-06T10:46:23.529745Z","iopub.status.idle":"2024-11-06T10:46:23.535732Z","shell.execute_reply.started":"2024-11-06T10:46:23.529706Z","shell.execute_reply":"2024-11-06T10:46:23.534638Z"}},"outputs":[{"name":"stdout","text":"./data/MNIST\n./hparams/params.json\ngan\nFalse\n./logs\n0\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Train functions\n\ndef update_discriminator(x, discriminator, generator, optimizer, params):\n    bs = x.size(0)\n    device = x.device\n\n    optimizer.zero_grad()\n\n    # for data (ground-truth) distribution\n    disc_real = discriminator(x)\n    loss_real = eval('compute_loss_'+args.model)(disc_real, loss_type='real')\n\n    # for generator distribution\n    latent = torch.randn(bs, params[\"dim_latent\"], device=device)\n    img_fake = generator(latent)\n    disc_fake = discriminator(img_fake.detach())\n    loss_fake = eval('compute_loss_'+args.model)(disc_fake, loss_type='fake')\n\n\n    loss_d = loss_real + loss_fake\n    loss_d.backward()\n    optimizer.step()\n\n\ndef update_generator(num_class, discriminator, generator, optimizer, params, device):\n    optimizer.zero_grad()\n\n    bs = params['batch_size']\n    latent = torch.randn(bs, params[\"dim_latent\"], device=device)\n\n    batch_fake = generator(latent)\n\n    disc_gen = discriminator(batch_fake)\n    loss_g = - disc_gen.mean()\n    loss_g.backward()\n    optimizer.step()\n\n\ndef compute_loss_gan(disc, loss_type):\n    assert (loss_type in ['real', 'fake'])\n    if 'real' == loss_type:\n        loss = (1. - disc).relu().mean() # Hinge loss\n    else: # 'fake' == loss_type\n        loss = (1. + disc).relu().mean() # Hinge loss\n\n    return loss\n\n\ndef compute_loss_san(disc, loss_type):\n    assert (loss_type in ['real', 'fake'])\n    if 'real' == loss_type:\n        loss_fun = (1. - disc['fun']).relu().mean() # Hinge loss for function h\n        loss_dir = - disc['dir'].mean() # Wasserstein loss for omega\n    else: # 'fake' == loss_type\n        loss_fun = (1. + disc['fun']).relu().mean() # Hinge loss for function h\n        loss_dir = disc['dir'].mean() # Wasserstein loss for omega\n    loss = loss_fun + loss_dir\n\n    return loss\n\n\ndef save_images(imgs, idx, dirname='test'):\n    import numpy as np\n    if imgs.shape[1] == 1:\n        imgs = np.repeat(imgs, 3, axis=1)\n    fig = plt.figure(figsize=(10, 10))\n    gs = gridspec.GridSpec(10, 10)\n    gs.update(wspace=0.05, hspace=0.05)\n    for i, sample in enumerate(imgs):\n        ax = plt.subplot(gs[i])\n        plt.axis('off')\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        ax.set_aspect('equal')\n        plt.imshow(sample.transpose((1,2,0)))\n\n    if not os.path.exists('out/{}/'.format(dirname)):\n        os.makedirs('out/{}/'.format(dirname))\n    plt.savefig('out/{0}/{1}.png'.format(dirname, str(idx).zfill(3)), bbox_inches=\"tight\")\n    plt.close(fig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:48:07.413265Z","iopub.execute_input":"2024-11-06T10:48:07.414146Z","iopub.status.idle":"2024-11-06T10:48:07.432086Z","shell.execute_reply.started":"2024-11-06T10:48:07.414099Z","shell.execute_reply":"2024-11-06T10:48:07.43111Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"device = f'cuda:{args.device}' if args.device is not None else 'cpu'\nmodel_name = args.model\nif not model_name in ['gan', 'san']:\n    raise RuntimeError(\"A model name have to be 'gan' or 'san'.\")\n    \nexperiment_name = model_name + \"_cond\" if args.enable_class else model_name\n\n# dataloading\nnum_class = 10\ntrain_dataset = datasets.MNIST(root=args.datadir, transform=transforms.ToTensor(), train=True, download=True)\ntrain_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], num_workers=4,\n                          pin_memory=True, persistent_workers=True, shuffle=True)\ntest_dataset = datasets.MNIST(root=args.datadir, transform=transforms.ToTensor(), train=False, download=True)\ntest_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], num_workers=4,\n                         pin_memory=True, persistent_workers=True, shuffle=False)\n\n# model\nuse_class = args.enable_class\ngenerator = Generator(g_output_dim=784)\n\nif 'gan' == args.model:\n    discriminator = BaseDiscriminator(input_dim=784)\n    #discriminator = BaseDiscriminator(num_class=num_class if use_class else 0)\nelse: # 'san' == args.model\n    discriminator = SanDiscriminator(num_class=num_class if use_class else 0)\ngenerator = generator.to(device)\ndiscriminator = discriminator.to(device)\n\n# optimizer\nbetas = (params[\"beta_1\"], params[\"beta_2\"])\noptimizer_G = optim.Adam(generator.parameters(), lr=params[\"learning_rate\"], betas=betas)\noptimizer_D = optim.Adam(discriminator.parameters(), lr=params[\"learning_rate\"], betas=betas)\n\nckpt_dir = f'{args.logdir}/{experiment_name}/'\nif not os.path.exists(args.logdir):\n    os.mkdir(args.logdir)\nif not os.path.exists(ckpt_dir):\n    os.mkdir(ckpt_dir)\n\nsteps_per_epoch = len(train_loader)\n\nmsg = [\"\\t{0}: {1}\".format(key, val) for key, val in params.items()]\nprint(\"hyperparameters: \\n\" + \"\\n\".join(msg))\n\n# eval initial states\nnum_samples_per_class = 10\nwith torch.no_grad():\n    latent = torch.randn(num_samples_per_class * num_class, params[\"dim_latent\"]).cuda()\n    imgs_fake = generator(latent)\n\n# main training loop\nfor n in range(params[\"num_epochs\"]):\n    loader = iter(train_loader)\n\n    print(\"epoch: {0}/{1}\".format(n + 1, params[\"num_epochs\"]))\n    for i in tqdm.trange(steps_per_epoch):\n        x, class_ids = next(loader)\n        x = x.to(device)\n\n        update_discriminator(x, discriminator, generator, optimizer_D, params)\n        update_generator(num_class, discriminator, generator, optimizer_G, params, device)\n\n    torch.save(generator.state_dict(), ckpt_dir + \"g.\" + str(n) + \".tmp\")\n    torch.save(discriminator.state_dict(), ckpt_dir + \"d.\" + str(n) + \".tmp\")\n\n    # eval\n    with torch.no_grad():\n        latent = torch.randn(num_samples_per_class * num_class, params[\"dim_latent\"]).cuda()\n        imgs_fake = generator(latent).cpu().data.numpy()\n        save_images(imgs_fake, n, dirname=experiment_name)\n\ntorch.save(generator.state_dict(), ckpt_dir + \"generator.pt\")\ntorch.save(discriminator.state_dict(), ckpt_dir + \"discriminator.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:49:02.435342Z","iopub.execute_input":"2024-11-06T10:49:02.436517Z","iopub.status.idle":"2024-11-06T10:49:03.070147Z","shell.execute_reply.started":"2024-11-06T10:49:02.436457Z","shell.execute_reply":"2024-11-06T10:49:03.066962Z"}},"outputs":[{"name":"stdout","text":"hyperparameters: \n\tdim_latent: 100\n\tbatch_size: 128\n\tlearning_rate: 0.001\n\tbeta_1: 0.0\n\tbeta_2: 0.99\n\tnum_epochs: 2\nepoch: 1/2\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/469 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m     x, class_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(loader)\n\u001b[1;32m     58\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mupdate_discriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     update_generator(num_class, discriminator, generator, optimizer_G, params, device)\n\u001b[1;32m     63\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(generator\u001b[38;5;241m.\u001b[39mstate_dict(), ckpt_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(n) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[18], line 10\u001b[0m, in \u001b[0;36mupdate_discriminator\u001b[0;34m(x, discriminator, generator, optimizer, params)\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# for data (ground-truth) distribution\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m disc_real \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompute_loss_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)(disc_real, loss_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# for generator distribution\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[11], line 19\u001b[0m, in \u001b[0;36mBaseDiscriminator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):        \n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Pass input through the fully connected layers\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x), \u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     21\u001b[0m     h_feature \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x), \u001b[38;5;241m0.2\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x1024)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x1024)","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T10:38:30.572242Z","iopub.status.idle":"2024-11-06T10:38:30.572628Z","shell.execute_reply.started":"2024-11-06T10:38:30.572437Z","shell.execute_reply":"2024-11-06T10:38:30.572456Z"}},"outputs":[],"execution_count":null}]}